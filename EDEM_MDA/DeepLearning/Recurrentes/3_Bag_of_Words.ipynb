{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words\n",
        "\n",
        "En este notebook vamos a ver un ejemplo práctico de la técnica de \"Bag of Words\".\n",
        "\n",
        "Como hemos visto, cuando operamos con textos, no hay ninguna operación matemática definida que pueda trabajar con ellos directamente. Por ejemplo, no podemos combinar las palabras _\"hola\"_ y _\"adiós\"_.\n",
        "\n",
        "Por lo tanto, para poder utilizar textos definidos en lenguaje natural, independientemente del idioma utilizado, necesitamos **transformar estos textos en vectores numéricos** que los representen.\n",
        "\n",
        "La técnica más conocida para hacer esta transformación se llama ***bolsa de palabras*** o **Bag of Words**.\n",
        "\n",
        "Veamos cómo funciona con un ejemplo. Supongamos que tenemos el siguiente texto\n",
        "\n",
        "> *El miedo es el camino hacia el Lado Oscuro. El miedo lleva a la ira, la ira lleva al odio, el odio lleva al sufrimiento. Percibo mucho miedo en ti.* — Yoda a Anakin en el Consejo Jedi.\n",
        "\n",
        "El primer paso que debemos realizar es la limpieza del dataset de caracteres extraños y homogeneizarlo a minúsculas:\n",
        "\n",
        "> el miedo es el camino hacia el lado oscuro el miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento percibo mucho miedo en ti\n",
        "\n",
        "Después, procederemos con la **tokenización**, que consiste en transformar el texto anterior en una matriz de palabras.\n",
        "\n",
        "Es decir, vamos a separar cada una de las palabras que componen la frase anterior utilizando espacios separadores. Por tanto, obtendríamos la siguiente lista de *tokens*:\n",
        "\n",
        "`['el', 'miedo', 'es', 'el', 'camino, 'hacia', 'el', 'lado', 'oscuro', 'el', 'miedo', 'lleva', 'a', 'la', 'ira', 'la', 'ira', 'lleva', 'al', 'odio', 'el', 'odio', 'lleva', 'al', 'sufrimiento', 'percibo', 'mucho', 'miedo', 'en', 'ti']`.\n",
        "\n",
        "A partir de la lista anterior podemos construir un **diccionario** que contenga todas las palabras definidas en nuestro vocabulario.\n",
        "\n",
        "Entendemos por \"nuestro vocabulario\" las palabras que aparecen en los textos que estamos analizando. Así, analizando los *tokens* anteriores construiremos el siguiente diccionario:\n",
        "\n",
        "`['el', 'miedo', 'es', 'camino, 'hacia', 'lado', 'oscuro', 'lleva', 'a', 'la', 'ira', 'al', 'odio', 'sufrimiento', 'percibo', 'mucho', 'en', 'ti']`\n",
        "\n",
        "Por último, tenemos que transformar el texto original en un vector numérico de forma que las posiciones del vector representen las posiciones de las palabras del diccionario y los valores del vector representen el número de apariciones de la palabra del diccionario en el texto analizado.\n",
        "\n",
        "Dado que nuestro diccionario consta de 18 palabras, nuestro texto quedaría definido por el siguiente vector\n",
        "\n",
        "`[5, 3, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1]`\n",
        "\n",
        "Viéndolo en formato tabla es más fácil de detectar:\n",
        "\n",
        "| | el | miedo | es | camino | hacia | lado | oscuro | lleva | a | la | ira | al | odio | sufrimiento | percibo | mucho | en | ti |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| Frecuencia | 5 | 3 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 2 | 2 | 2 | 2 | 1 | 1 | 1 | 1 | 1 |\n",
        "\n",
        "Analizándolo vemos que la palabra *'miedo'* se repite 3 veces, la palabra *'ira'* 2, la palabra *'el'* 5, y así sucesivamente."
      ],
      "metadata": {
        "id": "XSW84neQ4PdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso hemos dejado la limpieza de las stop-words para después, pues nos interesaba ver el cambio entre el antes y el después.\n",
        "\n",
        "Si eliminaramos las stop-words veríamos que desparecen los artículos, determinantes, preposiciones, etc.\n",
        "\n",
        "En lugar de hacerlo manualmente, como hasta ahora, vamos a hacerlo con Python."
      ],
      "metadata": {
        "id": "0d0cwDCs8LlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La forma más rápida de hacerlo es utilizando el objeto `CountVectorizer` del paquete `feature_extraction.text` de la librería `scikit-learn`.\n"
      ],
      "metadata": {
        "id": "qj4TXhJy5Oo5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.029322Z",
          "start_time": "2020-03-02T13:43:38.865734Z"
        },
        "id": "QzzEeRLsFxyS"
      },
      "source": [
        "import sklearn\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.038618Z",
          "start_time": "2020-03-02T13:43:39.030666Z"
        },
        "id": "O4_vzJSlU68R"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.043934Z",
          "start_time": "2020-03-02T13:43:39.040135Z"
        },
        "id": "rrkeG7G2VHRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7282d6-836a-4633-ff11-98c22d264a21"
      },
      "source": [
        "corpus = [\n",
        "    \"El miedo es el camino hacia el Lado Oscuro. El miedo lleva a la ira, la ira lleva al odio, el odio lleva al sufrimiento. Percibo mucho miedo en ti.\"\n",
        "]\n",
        "\n",
        "X = count_vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(X.toarray())\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 1 5 1 1 1 2 2 1 3 3 1 2 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2JPvuPCVEs9"
      },
      "source": [
        "Podemos ver el mapeo mediante la función `get_feature_names_out()`. Como podéis observar, ésta función detecta los símbolos de puntuación y los ignora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.052240Z",
          "start_time": "2020-03-02T13:43:39.049943Z"
        },
        "id": "uUXOKN5eWP9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64963c89-8191-40ab-809b-d1e6d89a2dc8"
      },
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['al' 'camino' 'el' 'en' 'es' 'hacia' 'ira' 'la' 'lado' 'lleva' 'miedo'\n",
            " 'mucho' 'odio' 'oscuro' 'percibo' 'sufrimiento' 'ti']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos ahora si elimináramos las stop-words:"
      ],
      "metadata": {
        "id": "wLCdq7vX9DPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install -U nltk"
      ],
      "metadata": {
        "id": "YLlSPoPWIZkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9885d38-d545-413d-adb5-e35373499bb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "IypXswWNU9HT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb99d27-fcc0-4c95-decf-7f5298624658"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, es necesario limpiar el dataset y homogeneizar a minusculas antes de usar `nltk`:"
      ],
      "metadata": {
        "id": "dXJ4tIRR9jSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "print(string.punctuation)"
      ],
      "metadata": {
        "id": "r4mYsq2LTZ7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5742d1a-c4bd-45f1-dafc-222754e392d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# añadimos algunos más que no están en string.punctuation, como las comillas y\n",
        "# las aperturas de interrogación/exclamación\n",
        "# si no los añadiésemos, no se eliminarían\n",
        "chars = string.punctuation + '“”¡¿'\n",
        "print(chars)"
      ],
      "metadata": {
        "id": "8zz8eWS4UCf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ad98ac-a369-4ac4-9271-a7785871bd10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~“”¡¿\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re_punc = re.compile('[%s]' % re.escape(chars))\n",
        "# eliminar la puntuación de cada palabra\n",
        "texto = re_punc.sub('', corpus[0])\n",
        "print(texto)"
      ],
      "metadata": {
        "id": "dntEu4LYTiDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02e4899-23ab-448e-d969-69ab2762cef0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El miedo es el camino hacia el Lado Oscuro El miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento Percibo mucho miedo en ti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos el texto a minúsculas:"
      ],
      "metadata": {
        "id": "EpHXy9LaHt18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = texto.lower()\n",
        "print(texto)"
      ],
      "metadata": {
        "id": "c8nsuU31ISMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff29382f-1b09-49f9-b4cf-605563e7e045"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el miedo es el camino hacia el lado oscuro el miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento percibo mucho miedo en ti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('spanish')\n",
        "palabras = texto.split(' ')\n",
        "print(palabras)"
      ],
      "metadata": {
        "id": "xDc8TzzewziV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf342d0-e4f1-4827-83f3-11b0da868a37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['el', 'miedo', 'es', 'el', 'camino', 'hacia', 'el', 'lado', 'oscuro', 'el', 'miedo', 'lleva', 'a', 'la', 'ira', 'la', 'ira', 'lleva', 'al', 'odio', 'el', 'odio', 'lleva', 'al', 'sufrimiento', 'percibo', 'mucho', 'miedo', 'en', 'ti']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos las stop-words:"
      ],
      "metadata": {
        "id": "9SZiAtvf-DE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_limpias = [p for p in palabras if p not in stop_words]\n",
        "print(palabras_limpias)"
      ],
      "metadata": {
        "id": "lSyfyWO79dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abe143d-4039-4c9b-bd27-243b02bb85d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['miedo', 'camino', 'hacia', 'lado', 'oscuro', 'miedo', 'lleva', 'ira', 'ira', 'lleva', 'odio', 'odio', 'lleva', 'sufrimiento', 'percibo', 'miedo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unimos el texto de nuevo:"
      ],
      "metadata": {
        "id": "GvWLiMSv-njd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_limpio = ' '.join(palabras_limpias)\n",
        "print(texto_limpio)"
      ],
      "metadata": {
        "id": "hSXYC4OS-ouF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e473d1-fc01-48c8-97e7-fe0d1b1a9aab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "miedo camino hacia lado oscuro miedo lleva ira ira lleva odio odio lleva sufrimiento percibo miedo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y aplicamos la técnica de Bag of Words:"
      ],
      "metadata": {
        "id": "J8iAu8pg-FUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "X = count_vectorizer.fit_transform([texto_limpio])\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "O1L7-zyg-IhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f20734-af60-4f04-d60b-01bff3f4461e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 2 1 3 3 2 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "Aq6UTNu7-dBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e467cccc-41a0-43a4-fa21-d7c4e79fc481"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['camino' 'hacia' 'ira' 'lado' 'lleva' 'miedo' 'odio' 'oscuro' 'percibo'\n",
            " 'sufrimiento']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparadlo con la versión sin limpiar:"
      ],
      "metadata": {
        "id": "bHYW85bn-yvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "X = count_vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "y4h-fv92-4K8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922060cc-8b24-41eb-b8f5-93270a7814ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 1 5 1 1 1 2 2 1 3 3 1 2 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "s7KUBXAP-4K_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1897f51e-2235-4c15-d389-226f8f946aea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['al' 'camino' 'el' 'en' 'es' 'hacia' 'ira' 'la' 'lado' 'lleva' 'miedo'\n",
            " 'mucho' 'odio' 'oscuro' 'percibo' 'sufrimiento' 'ti']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 1\n",
        "\n",
        "Realiza la limpieza del dataset, la eliminación de stop-words y la vectorización del texto (bag of words) del siguiente texto:\n",
        "\n",
        "> \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\" - Maestre Aemon, Juego de Tronos"
      ],
      "metadata": {
        "id": "kxiWIveA88_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = ['¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.']"
      ],
      "metadata": {
        "id": "4lQuM5Xn_X0L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Asegúrate de tener las stopwords descargadas\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Texto a limpiar\n",
        "texto = ['¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.']\n",
        "\n",
        "# Unir el texto en un solo string\n",
        "texto = ' '.join(texto)\n",
        "\n",
        "# Crear una expresión regular para eliminar símbolos de puntuación y caracteres no deseados\n",
        "pattern = r'[^\\w\\s]'\n",
        "\n",
        "# Usar re.sub para reemplazar los caracteres que coinciden con la expresión regular\n",
        "texto_limpio = re.sub(pattern, '', texto)\n",
        "\n",
        "# Convertir el texto limpio a minúsculas\n",
        "texto_limpio_minusculas = texto_limpio.lower()\n",
        "\n",
        "# Eliminar acentos del texto\n",
        "def eliminar_acentos(texto):\n",
        "    # Normalizar el texto en la forma NFD (Normalization Form D)\n",
        "    texto_normalizado = unicodedata.normalize('NFD', texto)\n",
        "    # Filtrar los caracteres que no son de composición (excluir los diacríticos)\n",
        "    texto_sin_acentos = ''.join(c for c in texto_normalizado if unicodedata.category(c) != 'Mn')\n",
        "    return texto_sin_acentos\n",
        "\n",
        "texto_final = eliminar_acentos(texto_limpio_minusculas)\n",
        "\n",
        "# Dividir el texto en palabras\n",
        "lista_palabras = texto_final.split()\n",
        "\n",
        "# Eliminar las stop-words\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "lista_palabras_sin_stopwords = [palabra for palabra in lista_palabras if palabra not in stop_words]\n",
        "\n",
        "print(\"\\nLista de palabras sin stop-words:\")\n",
        "print(lista_palabras_sin_stopwords)\n"
      ],
      "metadata": {
        "id": "G8O4Zc1953CB",
        "outputId": "1f741d60-593c-4480-d99c-f0e7e386bc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lista de palabras sin stop-words:\n",
            "['honor', 'comparado', 'amor', 'mujer', 'deber', 'comparado', 'calor', 'hijo', 'recien', 'nacido', 'brazos', 'recuerdo', 'sonrisa', 'hermano', 'aire', 'palabras', 'aire', 'palabras', 'solo', 'humanos', 'dioses', 'hicieron', 'amor', 'mayor', 'gloria', 'peor', 'tragedia']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Volver a unir las palabras limpias en un texto limpio final\n",
        "texto_limpio_final = ' '.join(lista_palabras_sin_stopwords)\n",
        "print(\"\\nTexto limpio final:\")\n",
        "print(texto_limpio_final)\n",
        "\n",
        "# Vectorización (Bag of Words) usando CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "X = count_vectorizer.fit_transform([texto_limpio_final])\n",
        "\n",
        "# Imprimir el resultado de la vectorización\n",
        "print(\"\\nVectorización (Bag of Words):\")\n",
        "print(X.toarray())\n",
        "\n",
        "print(\"\\nCaracterísticas (palabras):\")\n",
        "print(count_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "r75nSMGQ6_fG",
        "outputId": "f1bcdf9e-0b92-42eb-8f12-ff762734a0d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto limpio final:\n",
            "honor comparado amor mujer deber comparado calor hijo recien nacido brazos recuerdo sonrisa hermano aire palabras aire palabras solo humanos dioses hicieron amor mayor gloria peor tragedia\n",
            "\n",
            "Vectorización (Bag of Words):\n",
            "[[2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n",
            "\n",
            "Características (palabras):\n",
            "['aire' 'amor' 'brazos' 'calor' 'comparado' 'deber' 'dioses' 'gloria'\n",
            " 'hermano' 'hicieron' 'hijo' 'honor' 'humanos' 'mayor' 'mujer' 'nacido'\n",
            " 'palabras' 'peor' 'recien' 'recuerdo' 'solo' 'sonrisa' 'tragedia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 2\n",
        "\n",
        "Realiza la limpieza del dataset, la eliminación de stop-words y la vectorización del texto (bag of words) del siguiente *corpus* de documentos:\n",
        "\n",
        "> \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\" - Cersei Lannister\n",
        "\n",
        "> \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\" - Tyrion Lannister\n",
        "\n",
        "> \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\" - Maestre Aemon, Juego de Tronos\n",
        "\n",
        "> \"El hombre que dicta la condena debe blandir la espada.\" - Eddard Stark\n",
        "\n",
        "> \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\" - Lord Varys"
      ],
      "metadata": {
        "id": "_rWIR9XACDvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = [\n",
        "    \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\",\n",
        "    \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\",\n",
        "    \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\",\n",
        "    \"El hombre que dicta la condena debe blandir la espada.\",\n",
        "    \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\"\n",
        "]"
      ],
      "metadata": {
        "id": "uqug2lmKCDvO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Asegúrate de tener las stopwords descargadas\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Texto a limpiar\n",
        "texto = [\n",
        "    \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\",\n",
        "    \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\",\n",
        "    \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\",\n",
        "    \"El hombre que dicta la condena debe blandir la espada.\",\n",
        "    \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\"\n",
        "]\n",
        "\n",
        "# Unir el texto en un solo string\n",
        "texto = ' '.join(texto)\n",
        "\n",
        "# Crear una expresión regular para eliminar símbolos de puntuación y caracteres no deseados\n",
        "pattern = r'[^\\w\\s]'\n",
        "\n",
        "# Usar re.sub para reemplazar los caracteres que coinciden con la expresión regular\n",
        "texto_limpio = re.sub(pattern, '', texto)\n",
        "\n",
        "# Convertir el texto limpio a minúsculas\n",
        "texto_limpio_minusculas = texto_limpio.lower()\n",
        "\n",
        "# Eliminar acentos del texto\n",
        "def eliminar_acentos(texto):\n",
        "    # Normalizar el texto en la forma NFD (Normalization Form D)\n",
        "    texto_normalizado = unicodedata.normalize('NFD', texto)\n",
        "    # Filtrar los caracteres que no son de composición (excluir los diacríticos)\n",
        "    texto_sin_acentos = ''.join(c for c in texto_normalizado if unicodedata.category(c) != 'Mn')\n",
        "    return texto_sin_acentos\n",
        "\n",
        "texto_final = eliminar_acentos(texto_limpio_minusculas)\n",
        "\n",
        "# Dividir el texto en palabras\n",
        "lista_palabras = texto_final.split()\n",
        "\n",
        "# Eliminar las stop-words\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "lista_palabras_sin_stopwords = [palabra for palabra in lista_palabras if palabra not in stop_words]\n",
        "\n",
        "print(\"\\nLista de palabras sin stop-words:\")\n",
        "print(lista_palabras_sin_stopwords)\n",
        "\n",
        "# Volver a unir las palabras limpias en un texto limpio final\n",
        "texto_limpio_final = ' '.join(lista_palabras_sin_stopwords)\n",
        "print(\"\\nTexto limpio final:\")\n",
        "print(texto_limpio_final)\n",
        "\n",
        "# Vectorización (Bag of Words) usando CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "X = count_vectorizer.fit_transform([texto_limpio_final])\n",
        "\n",
        "# Imprimir el resultado de la vectorización\n",
        "print(\"\\nVectorización (Bag of Words):\")\n",
        "print(X.toarray())\n",
        "\n",
        "print(\"\\nCaracterísticas (palabras):\")\n",
        "print(count_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "id": "qlRTxIFz7Zsz",
        "outputId": "0c391068-4f2d-4b98-d0d7-57e31e808aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lista de palabras sin stop-words:\n",
            "['juega', 'juego', 'tronos', 'solo', 'puede', 'ganar', 'morir', 'sera', 'cuanto', 'hombre', 'construye', 'muro', 'vecino', 'inmediatamente', 'quiere', 'saber', 'lado', 'honor', 'comparado', 'amor', 'mujer', 'deber', 'comparado', 'calor', 'hijo', 'recien', 'nacido', 'brazos', 'recuerdo', 'sonrisa', 'hermano', 'aire', 'palabras', 'aire', 'palabras', 'solo', 'humanos', 'dioses', 'hicieron', 'amor', 'mayor', 'gloria', 'peor', 'tragedia', 'hombre', 'dicta', 'condena', 'debe', 'blandir', 'espada', 'poder', 'reside', 'hombres', 'creen', 'reside', 'truco', 'sombra', 'pared', 'hombre', 'pequeno', 'puede', 'proyectar', 'sombra', 'grande']\n",
            "\n",
            "Texto limpio final:\n",
            "juega juego tronos solo puede ganar morir sera cuanto hombre construye muro vecino inmediatamente quiere saber lado honor comparado amor mujer deber comparado calor hijo recien nacido brazos recuerdo sonrisa hermano aire palabras aire palabras solo humanos dioses hicieron amor mayor gloria peor tragedia hombre dicta condena debe blandir espada poder reside hombres creen reside truco sombra pared hombre pequeno puede proyectar sombra grande\n",
            "\n",
            "Vectorización (Bag of Words):\n",
            "[[2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
            "  1 1 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 1]]\n",
            "\n",
            "Características (palabras):\n",
            "['aire' 'amor' 'blandir' 'brazos' 'calor' 'comparado' 'condena'\n",
            " 'construye' 'creen' 'cuanto' 'debe' 'deber' 'dicta' 'dioses' 'espada'\n",
            " 'ganar' 'gloria' 'grande' 'hermano' 'hicieron' 'hijo' 'hombre' 'hombres'\n",
            " 'honor' 'humanos' 'inmediatamente' 'juega' 'juego' 'lado' 'mayor' 'morir'\n",
            " 'mujer' 'muro' 'nacido' 'palabras' 'pared' 'peor' 'pequeno' 'poder'\n",
            " 'proyectar' 'puede' 'quiere' 'recien' 'recuerdo' 'reside' 'saber' 'sera'\n",
            " 'solo' 'sombra' 'sonrisa' 'tragedia' 'tronos' 'truco' 'vecino']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}