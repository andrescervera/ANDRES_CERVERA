{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec\n",
        "\n",
        "En este notebook, vamos a crear un modelo Word2Vec utilizando texto de un artículo de la wikipedia.\n",
        "\n",
        "Para ello, lo primero que vamos a hacer es instalar las dependencias necesarias. Necesitaremos `beautifulsoup` para hacer el *scrapping* del texto y `lxml` para parsear el código `html` que nos encontremos y poder extraer, por ejemplo, únicamente los párrafos."
      ],
      "metadata": {
        "id": "646aYU8JiKHb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kXeTMM7kiGaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a413b1c-2e26-4529-cd6a-3e00f7ece7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora realizaremos los imports necesarios:"
      ],
      "metadata": {
        "id": "8jPu-FLNj9iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "O84jqPOSidxV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y seguidamente descargaremos los paquetes que `nltk` necesita para funcionar:"
      ],
      "metadata": {
        "id": "BUBozWa7kjXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "3-7RXtnIig2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c795ef-e064-4809-cd46-65f087c56bd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya tenemos el software necesario preparado. Ahora vamos a escoger una página de la Wikipedia para obtener todos los párrafos que se encuentren en ella y utilizarlos como nuestro *corpus*.\n",
        "\n",
        "Para ello, utilizaremos la librería `urllib` de Python:"
      ],
      "metadata": {
        "id": "01s51rSpkqEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos_wikipedia = urllib.request.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')"
      ],
      "metadata": {
        "id": "vHtpg3MXintb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evitar problemas, necesitaremos convertir el texto en una codificación UTF-8:"
      ],
      "metadata": {
        "id": "YqKQX8PHk6i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articulo = datos_wikipedia.read().decode('utf-8')"
      ],
      "metadata": {
        "id": "x0VbyZNWiv-s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y ahora extraeremos todos los párrafos que existan en la página:"
      ],
      "metadata": {
        "id": "5cnSsoCWlA7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = bs.BeautifulSoup(articulo, 'lxml')\n",
        "parrafos = parser.find_all('p')"
      ],
      "metadata": {
        "id": "0Ugsw1m3izxM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguidamente, los concatenaremos en un único string:"
      ],
      "metadata": {
        "id": "LwavEPL0lHt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\n",
        "for p in parrafos:\n",
        "    texto += p.text"
      ],
      "metadata": {
        "id": "53J_u1Nri7Od"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto"
      ],
      "metadata": {
        "id": "Ikiyau37jA10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "225f0c17-c915-49c0-c6e1-aed9ac137233"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of \"understanding\"[citation needed] the contents of documents, including the contextual nuances of the language within them. To this end, natural language processing often borrows ideas from theoretical linguistics. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\\nChallenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\nNatural language processing has its roots in the 1940s.[1] Already in 1940, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\nThe premise of symbolic NLP is well-summarized by John Searle\\'s Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\\nIn 2003, word n-gram model, at the time the best statistical algorithm, was overperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling) by Yoshua Bengio with co-authors.[9]\\nIn 2010, Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,[10] and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. That popularity was due partly to a flurry of results showing that such techniques[11][12] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[13] and parsing.[14][15] This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care[16] or protect patient privacy.[17]\\nSymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\\nMachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \\nAlthough rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023. \\nBefore that they were commonly used:\\nIn the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\\nThe earliest decision trees, producing systems of hard if–then rules, were still very similar to the old rule-based approaches.\\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\\nA major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach was replaced by the neural networks approach, using word embeddings to capture semantic properties of words. \\nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) have not been needed anymore. \\nNeural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\\nThe following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\\nBased on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[45]\\nMost higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\\nCognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[46] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[47] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[48] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\\nAs an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[49] with two defining aspects:\\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[52] functional grammar,[53] construction grammar,[54] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[55] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[56] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[57] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[58] and new directions in artificial general intelligence based on the free energy principle[59] by British neuroscientist and theoretician at University College London Karl J. Friston.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-procesado\n",
        "\n",
        "Como ya sabemos, es muy importante limpiar el texto y eliminar las stop-words."
      ],
      "metadata": {
        "id": "a6pw1ddqjDhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpieza del texto\n",
        "\n",
        "Vamos a convertir el texto a minúsculas, luego a sustituir todos los caracteres que no sean letras por espacios, y por último a sustituir los espacios de forma que solo quede uno."
      ],
      "metadata": {
        "id": "UB7QrZBdjHBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = texto.lower()\n",
        "texto"
      ],
      "metadata": {
        "id": "ucIcZW0NjIN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "be660f85-26b8-4011-8069-8a98c73e9083"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing (nlp) is an interdisciplinary subfield of computer science and information retrieval. it is primarily concerned with giving computers the ability to support and manipulate human language. it involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. the goal is a computer capable of \"understanding\"[citation needed] the contents of documents, including the contextual nuances of the language within them. to this end, natural language processing often borrows ideas from theoretical linguistics. the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\\nchallenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\nnatural language processing has its roots in the 1940s.[1] already in 1940, alan turing published an article titled \"computing machinery and intelligence\" which proposed what is now called the turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. the proposed test includes a task that involves the automated interpretation and generation of natural language.\\nthe premise of symbolic nlp is well-summarized by john searle\\'s chinese room experiment: given a collection of rules (e.g., a chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other nlp tasks) by applying those rules to the data it confronts.\\nup until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  this was due to both the steady increase in computational power (see moore\\'s law) and the gradual lessening of the dominance of chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\\nin 2003, word n-gram model, at the time the best statistical algorithm, was overperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a cpu cluster in language modelling) by yoshua bengio with co-authors.[9]\\nin 2010, tomáš mikolov (then a phd student at brno university of technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,[10] and in the following years he went on to develop word2vec. in the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. that popularity was due partly to a flurry of results showing that such techniques[11][12] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[13] and parsing.[14][15] this is increasingly important in medicine and healthcare, where nlp helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care[16] or protect patient privacy.[17]\\nsymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by ai in general and by nlp in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\\nmachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \\nalthough rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of llms in 2023. \\nbefore that they were commonly used:\\nin the late 1980s and mid-1990s, the statistical approach ended a period of ai winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\\nthe earliest decision trees, producing systems of hard if–then rules, were still very similar to the old rule-based approaches.\\nonly the introduction of hidden markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\\na major drawback of statistical methods is that they require elaborate feature engineering. since 2015,[22] the statistical approach was replaced by the neural networks approach, using word embeddings to capture semantic properties of words. \\nintermediate tasks (e.g., part-of-speech tagging and dependency parsing) have not been needed anymore. \\nneural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\\nthe following is a list of some of the most commonly researched tasks in natural language processing. some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\nthough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. a coarse division is given below.\\nbased on long-standing trends in the field, it is possible to extrapolate future directions of nlp. as of 2020, three trends among the topics of the long-standing series of conll shared tasks can be observed:[45]\\nmost higher-level nlp applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. more broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of nlp (see trends among conll shared tasks above).\\ncognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[46] cognitive science is the interdisciplinary, scientific study of the mind and its processes.[47] cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[48] especially during the age of symbolic nlp, the area of computational linguistics maintained strong ties with cognitive studies.\\nas an example, george lakoff offers a methodology to build natural language processing (nlp) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[49] with two defining aspects:\\nties with cognitive linguistics are part of the historical heritage of nlp, but they have been less frequently addressed since the statistical turn during the 1990s. nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[52] functional grammar,[53] construction grammar,[54] computational psycholinguistics and cognitive neuroscience (e.g., act-r), however, with limited uptake in mainstream nlp (as measured by presence on major conferences[55] of the acl). more recently, ideas of cognitive nlp have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive ai\".[56] likewise, ideas of cognitive nlp are inherent to neural models multimodal nlp (although rarely made explicit)[57] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[58] and new directions in artificial general intelligence based on the free energy principle[59] by british neuroscientist and theoretician at university college london karl j. friston.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = re.sub(r'[^a-z]', ' ', texto)\n",
        "texto"
      ],
      "metadata": {
        "id": "eM0iQ7S7jKIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "bfd8c6bd-5abc-4f54-a462-0f10039937df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing  nlp  is an interdisciplinary subfield of computer science and information retrieval  it is primarily concerned with giving computers the ability to support and manipulate human language  it involves processing natural language datasets  such as text corpora or speech corpora  using either rule based or probabilistic  i e  statistical and  most recently  neural network based  machine learning approaches  the goal is a computer capable of  understanding  citation needed  the contents of documents  including the contextual nuances of the language within them  to this end  natural language processing often borrows ideas from theoretical linguistics  the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves  challenges in natural language processing frequently involve speech recognition  natural language understanding  and natural language generation  natural language processing has its roots in the     s     already in       alan turing published an article titled  computing machinery and intelligence  which proposed what is now called the turing test as a criterion of intelligence  though at the time that was not articulated as a problem separate from artificial intelligence  the proposed test includes a task that involves the automated interpretation and generation of natural language  the premise of symbolic nlp is well summarized by john searle s chinese room experiment  given a collection of rules  e g   a chinese phrasebook  with questions and matching answers   the computer emulates natural language understanding  or other nlp tasks  by applying those rules to the data it confronts  up until the     s  most natural language processing systems were based on complex sets of hand written rules   starting in the late     s  however  there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing   this was due to both the steady increase in computational power  see moore s law  and the gradual lessening of the dominance of chomskyan theories of linguistics  e g  transformational grammar   whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine learning approach to language processing     in       word n gram model  at the time the best statistical algorithm  was overperformed by a multi layer perceptron  with a single hidden layer and context length of several words trained on up to    million of words with a cpu cluster in language modelling  by yoshua bengio with co authors     in       tom   mikolov  then a phd student at brno university of technology  with co authors applied a simple recurrent neural network with a single hidden layer to language modelling      and in the following years he went on to develop word vec  in the     s  representation learning and deep neural network style  featuring many hidden layers  machine learning methods became widespread in natural language processing  that popularity was due partly to a flurry of results showing that such techniques         can achieve state of the art results in many natural language tasks  e g   in language modeling     and parsing          this is increasingly important in medicine and healthcare  where nlp helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care     or protect patient privacy      symbolic approach  i e   the hand coding of a set of rules for manipulating symbols  coupled with a dictionary lookup  was historically the first approach used both by ai in general and by nlp in particular          such as by writing grammars or devising heuristic rules for stemming  machine learning approaches  which include both statistical and neural networks  on the other hand  have many advantages over the symbolic approach   although rule based systems for manipulating symbols were still in use in       they have become mostly obsolete with the advance of llms in        before that they were commonly used  in the late     s and mid     s  the statistical approach ended a period of ai winter  which was caused by the inefficiencies of the rule based approaches          the earliest decision trees  producing systems of hard if then rules  were still very similar to the old rule based approaches  only the introduction of hidden markov models  applied to part of speech tagging  announced the end of the old rule based approach  a major drawback of statistical methods is that they require elaborate feature engineering  since           the statistical approach was replaced by the neural networks approach  using word embeddings to capture semantic properties of words   intermediate tasks  e g   part of speech tagging and dependency parsing  have not been needed anymore   neural machine translation  based on then newly invented sequence to sequence transformations  made obsolete the intermediate steps  such as word alignment  previously necessary for statistical machine translation  the following is a list of some of the most commonly researched tasks in natural language processing  some of these tasks have direct real world applications  while others more commonly serve as subtasks that are used to aid in solving larger tasks  though natural language processing tasks are closely intertwined  they can be subdivided into categories for convenience  a coarse division is given below  based on long standing trends in the field  it is possible to extrapolate future directions of nlp  as of       three trends among the topics of the long standing series of conll shared tasks can be observed      most higher level nlp applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language  more broadly speaking  the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of nlp  see trends among conll shared tasks above   cognition refers to  the mental action or process of acquiring knowledge and understanding through thought  experience  and the senses       cognitive science is the interdisciplinary  scientific study of the mind and its processes      cognitive linguistics is an interdisciplinary branch of linguistics  combining knowledge and research from both psychology and linguistics      especially during the age of symbolic nlp  the area of computational linguistics maintained strong ties with cognitive studies  as an example  george lakoff offers a methodology to build natural language processing  nlp  algorithms through the perspective of cognitive science  along with the findings of cognitive linguistics      with two defining aspects  ties with cognitive linguistics are part of the historical heritage of nlp  but they have been less frequently addressed since the statistical turn during the     s  nevertheless  approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks  e g   of cognitive grammar      functional grammar      construction grammar      computational psycholinguistics and cognitive neuroscience  e g   act r   however  with limited uptake in mainstream nlp  as measured by presence on major conferences     of the acl   more recently  ideas of cognitive nlp have been revived as an approach to achieve explainability  e g   under the notion of  cognitive ai       likewise  ideas of cognitive nlp are inherent to neural models multimodal nlp  although rarely made explicit      and developments in artificial intelligence  specifically tools and technologies using large language model approaches     and new directions in artificial general intelligence based on the free energy principle     by british neuroscientist and theoretician at university college london karl j  friston  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = re.sub(r'\\s+', ' ', texto)\n",
        "texto"
      ],
      "metadata": {
        "id": "Of6jZqZDjQX1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "9cec5fc1-e628-4a89-c730-80fbe3131bb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing nlp is an interdisciplinary subfield of computer science and information retrieval it is primarily concerned with giving computers the ability to support and manipulate human language it involves processing natural language datasets such as text corpora or speech corpora using either rule based or probabilistic i e statistical and most recently neural network based machine learning approaches the goal is a computer capable of understanding citation needed the contents of documents including the contextual nuances of the language within them to this end natural language processing often borrows ideas from theoretical linguistics the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves challenges in natural language processing frequently involve speech recognition natural language understanding and natural language generation natural language processing has its roots in the s already in alan turing published an article titled computing machinery and intelligence which proposed what is now called the turing test as a criterion of intelligence though at the time that was not articulated as a problem separate from artificial intelligence the proposed test includes a task that involves the automated interpretation and generation of natural language the premise of symbolic nlp is well summarized by john searle s chinese room experiment given a collection of rules e g a chinese phrasebook with questions and matching answers the computer emulates natural language understanding or other nlp tasks by applying those rules to the data it confronts up until the s most natural language processing systems were based on complex sets of hand written rules starting in the late s however there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing this was due to both the steady increase in computational power see moore s law and the gradual lessening of the dominance of chomskyan theories of linguistics e g transformational grammar whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine learning approach to language processing in word n gram model at the time the best statistical algorithm was overperformed by a multi layer perceptron with a single hidden layer and context length of several words trained on up to million of words with a cpu cluster in language modelling by yoshua bengio with co authors in tom mikolov then a phd student at brno university of technology with co authors applied a simple recurrent neural network with a single hidden layer to language modelling and in the following years he went on to develop word vec in the s representation learning and deep neural network style featuring many hidden layers machine learning methods became widespread in natural language processing that popularity was due partly to a flurry of results showing that such techniques can achieve state of the art results in many natural language tasks e g in language modeling and parsing this is increasingly important in medicine and healthcare where nlp helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care or protect patient privacy symbolic approach i e the hand coding of a set of rules for manipulating symbols coupled with a dictionary lookup was historically the first approach used both by ai in general and by nlp in particular such as by writing grammars or devising heuristic rules for stemming machine learning approaches which include both statistical and neural networks on the other hand have many advantages over the symbolic approach although rule based systems for manipulating symbols were still in use in they have become mostly obsolete with the advance of llms in before that they were commonly used in the late s and mid s the statistical approach ended a period of ai winter which was caused by the inefficiencies of the rule based approaches the earliest decision trees producing systems of hard if then rules were still very similar to the old rule based approaches only the introduction of hidden markov models applied to part of speech tagging announced the end of the old rule based approach a major drawback of statistical methods is that they require elaborate feature engineering since the statistical approach was replaced by the neural networks approach using word embeddings to capture semantic properties of words intermediate tasks e g part of speech tagging and dependency parsing have not been needed anymore neural machine translation based on then newly invented sequence to sequence transformations made obsolete the intermediate steps such as word alignment previously necessary for statistical machine translation the following is a list of some of the most commonly researched tasks in natural language processing some of these tasks have direct real world applications while others more commonly serve as subtasks that are used to aid in solving larger tasks though natural language processing tasks are closely intertwined they can be subdivided into categories for convenience a coarse division is given below based on long standing trends in the field it is possible to extrapolate future directions of nlp as of three trends among the topics of the long standing series of conll shared tasks can be observed most higher level nlp applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language more broadly speaking the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of nlp see trends among conll shared tasks above cognition refers to the mental action or process of acquiring knowledge and understanding through thought experience and the senses cognitive science is the interdisciplinary scientific study of the mind and its processes cognitive linguistics is an interdisciplinary branch of linguistics combining knowledge and research from both psychology and linguistics especially during the age of symbolic nlp the area of computational linguistics maintained strong ties with cognitive studies as an example george lakoff offers a methodology to build natural language processing nlp algorithms through the perspective of cognitive science along with the findings of cognitive linguistics with two defining aspects ties with cognitive linguistics are part of the historical heritage of nlp but they have been less frequently addressed since the statistical turn during the s nevertheless approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks e g of cognitive grammar functional grammar construction grammar computational psycholinguistics and cognitive neuroscience e g act r however with limited uptake in mainstream nlp as measured by presence on major conferences of the acl more recently ideas of cognitive nlp have been revived as an approach to achieve explainability e g under the notion of cognitive ai likewise ideas of cognitive nlp are inherent to neural models multimodal nlp although rarely made explicit and developments in artificial intelligence specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by british neuroscientist and theoretician at university college london karl j friston '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palabras = nltk.word_tokenize(texto)\n",
        "palabras"
      ],
      "metadata": {
        "id": "sscKIDX6jtgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abfbd3f-0c98-49cd-8b82-72b5c449d7ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'nlp',\n",
              " 'is',\n",
              " 'an',\n",
              " 'interdisciplinary',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'and',\n",
              " 'information',\n",
              " 'retrieval',\n",
              " 'it',\n",
              " 'is',\n",
              " 'primarily',\n",
              " 'concerned',\n",
              " 'with',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'support',\n",
              " 'and',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " 'it',\n",
              " 'involves',\n",
              " 'processing',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'datasets',\n",
              " 'such',\n",
              " 'as',\n",
              " 'text',\n",
              " 'corpora',\n",
              " 'or',\n",
              " 'speech',\n",
              " 'corpora',\n",
              " 'using',\n",
              " 'either',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'or',\n",
              " 'probabilistic',\n",
              " 'i',\n",
              " 'e',\n",
              " 'statistical',\n",
              " 'and',\n",
              " 'most',\n",
              " 'recently',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'based',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " 'the',\n",
              " 'goal',\n",
              " 'is',\n",
              " 'a',\n",
              " 'computer',\n",
              " 'capable',\n",
              " 'of',\n",
              " 'understanding',\n",
              " 'citation',\n",
              " 'needed',\n",
              " 'the',\n",
              " 'contents',\n",
              " 'of',\n",
              " 'documents',\n",
              " 'including',\n",
              " 'the',\n",
              " 'contextual',\n",
              " 'nuances',\n",
              " 'of',\n",
              " 'the',\n",
              " 'language',\n",
              " 'within',\n",
              " 'them',\n",
              " 'to',\n",
              " 'this',\n",
              " 'end',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'often',\n",
              " 'borrows',\n",
              " 'ideas',\n",
              " 'from',\n",
              " 'theoretical',\n",
              " 'linguistics',\n",
              " 'the',\n",
              " 'technology',\n",
              " 'can',\n",
              " 'then',\n",
              " 'accurately',\n",
              " 'extract',\n",
              " 'information',\n",
              " 'and',\n",
              " 'insights',\n",
              " 'contained',\n",
              " 'in',\n",
              " 'the',\n",
              " 'documents',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'categorize',\n",
              " 'and',\n",
              " 'organize',\n",
              " 'the',\n",
              " 'documents',\n",
              " 'themselves',\n",
              " 'challenges',\n",
              " 'in',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'frequently',\n",
              " 'involve',\n",
              " 'speech',\n",
              " 'recognition',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " 'and',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'generation',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'has',\n",
              " 'its',\n",
              " 'roots',\n",
              " 'in',\n",
              " 'the',\n",
              " 's',\n",
              " 'already',\n",
              " 'in',\n",
              " 'alan',\n",
              " 'turing',\n",
              " 'published',\n",
              " 'an',\n",
              " 'article',\n",
              " 'titled',\n",
              " 'computing',\n",
              " 'machinery',\n",
              " 'and',\n",
              " 'intelligence',\n",
              " 'which',\n",
              " 'proposed',\n",
              " 'what',\n",
              " 'is',\n",
              " 'now',\n",
              " 'called',\n",
              " 'the',\n",
              " 'turing',\n",
              " 'test',\n",
              " 'as',\n",
              " 'a',\n",
              " 'criterion',\n",
              " 'of',\n",
              " 'intelligence',\n",
              " 'though',\n",
              " 'at',\n",
              " 'the',\n",
              " 'time',\n",
              " 'that',\n",
              " 'was',\n",
              " 'not',\n",
              " 'articulated',\n",
              " 'as',\n",
              " 'a',\n",
              " 'problem',\n",
              " 'separate',\n",
              " 'from',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'the',\n",
              " 'proposed',\n",
              " 'test',\n",
              " 'includes',\n",
              " 'a',\n",
              " 'task',\n",
              " 'that',\n",
              " 'involves',\n",
              " 'the',\n",
              " 'automated',\n",
              " 'interpretation',\n",
              " 'and',\n",
              " 'generation',\n",
              " 'of',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'the',\n",
              " 'premise',\n",
              " 'of',\n",
              " 'symbolic',\n",
              " 'nlp',\n",
              " 'is',\n",
              " 'well',\n",
              " 'summarized',\n",
              " 'by',\n",
              " 'john',\n",
              " 'searle',\n",
              " 's',\n",
              " 'chinese',\n",
              " 'room',\n",
              " 'experiment',\n",
              " 'given',\n",
              " 'a',\n",
              " 'collection',\n",
              " 'of',\n",
              " 'rules',\n",
              " 'e',\n",
              " 'g',\n",
              " 'a',\n",
              " 'chinese',\n",
              " 'phrasebook',\n",
              " 'with',\n",
              " 'questions',\n",
              " 'and',\n",
              " 'matching',\n",
              " 'answers',\n",
              " 'the',\n",
              " 'computer',\n",
              " 'emulates',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " 'or',\n",
              " 'other',\n",
              " 'nlp',\n",
              " 'tasks',\n",
              " 'by',\n",
              " 'applying',\n",
              " 'those',\n",
              " 'rules',\n",
              " 'to',\n",
              " 'the',\n",
              " 'data',\n",
              " 'it',\n",
              " 'confronts',\n",
              " 'up',\n",
              " 'until',\n",
              " 'the',\n",
              " 's',\n",
              " 'most',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'systems',\n",
              " 'were',\n",
              " 'based',\n",
              " 'on',\n",
              " 'complex',\n",
              " 'sets',\n",
              " 'of',\n",
              " 'hand',\n",
              " 'written',\n",
              " 'rules',\n",
              " 'starting',\n",
              " 'in',\n",
              " 'the',\n",
              " 'late',\n",
              " 's',\n",
              " 'however',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'revolution',\n",
              " 'in',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'with',\n",
              " 'the',\n",
              " 'introduction',\n",
              " 'of',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'algorithms',\n",
              " 'for',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'this',\n",
              " 'was',\n",
              " 'due',\n",
              " 'to',\n",
              " 'both',\n",
              " 'the',\n",
              " 'steady',\n",
              " 'increase',\n",
              " 'in',\n",
              " 'computational',\n",
              " 'power',\n",
              " 'see',\n",
              " 'moore',\n",
              " 's',\n",
              " 'law',\n",
              " 'and',\n",
              " 'the',\n",
              " 'gradual',\n",
              " 'lessening',\n",
              " 'of',\n",
              " 'the',\n",
              " 'dominance',\n",
              " 'of',\n",
              " 'chomskyan',\n",
              " 'theories',\n",
              " 'of',\n",
              " 'linguistics',\n",
              " 'e',\n",
              " 'g',\n",
              " 'transformational',\n",
              " 'grammar',\n",
              " 'whose',\n",
              " 'theoretical',\n",
              " 'underpinnings',\n",
              " 'discouraged',\n",
              " 'the',\n",
              " 'sort',\n",
              " 'of',\n",
              " 'corpus',\n",
              " 'linguistics',\n",
              " 'that',\n",
              " 'underlies',\n",
              " 'the',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approach',\n",
              " 'to',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'in',\n",
              " 'word',\n",
              " 'n',\n",
              " 'gram',\n",
              " 'model',\n",
              " 'at',\n",
              " 'the',\n",
              " 'time',\n",
              " 'the',\n",
              " 'best',\n",
              " 'statistical',\n",
              " 'algorithm',\n",
              " 'was',\n",
              " 'overperformed',\n",
              " 'by',\n",
              " 'a',\n",
              " 'multi',\n",
              " 'layer',\n",
              " 'perceptron',\n",
              " 'with',\n",
              " 'a',\n",
              " 'single',\n",
              " 'hidden',\n",
              " 'layer',\n",
              " 'and',\n",
              " 'context',\n",
              " 'length',\n",
              " 'of',\n",
              " 'several',\n",
              " 'words',\n",
              " 'trained',\n",
              " 'on',\n",
              " 'up',\n",
              " 'to',\n",
              " 'million',\n",
              " 'of',\n",
              " 'words',\n",
              " 'with',\n",
              " 'a',\n",
              " 'cpu',\n",
              " 'cluster',\n",
              " 'in',\n",
              " 'language',\n",
              " 'modelling',\n",
              " 'by',\n",
              " 'yoshua',\n",
              " 'bengio',\n",
              " 'with',\n",
              " 'co',\n",
              " 'authors',\n",
              " 'in',\n",
              " 'tom',\n",
              " 'mikolov',\n",
              " 'then',\n",
              " 'a',\n",
              " 'phd',\n",
              " 'student',\n",
              " 'at',\n",
              " 'brno',\n",
              " 'university',\n",
              " 'of',\n",
              " 'technology',\n",
              " 'with',\n",
              " 'co',\n",
              " 'authors',\n",
              " 'applied',\n",
              " 'a',\n",
              " 'simple',\n",
              " 'recurrent',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'with',\n",
              " 'a',\n",
              " 'single',\n",
              " 'hidden',\n",
              " 'layer',\n",
              " 'to',\n",
              " 'language',\n",
              " 'modelling',\n",
              " 'and',\n",
              " 'in',\n",
              " 'the',\n",
              " 'following',\n",
              " 'years',\n",
              " 'he',\n",
              " 'went',\n",
              " 'on',\n",
              " 'to',\n",
              " 'develop',\n",
              " 'word',\n",
              " 'vec',\n",
              " 'in',\n",
              " 'the',\n",
              " 's',\n",
              " 'representation',\n",
              " 'learning',\n",
              " 'and',\n",
              " 'deep',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'style',\n",
              " 'featuring',\n",
              " 'many',\n",
              " 'hidden',\n",
              " 'layers',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'methods',\n",
              " 'became',\n",
              " 'widespread',\n",
              " 'in',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'that',\n",
              " 'popularity',\n",
              " 'was',\n",
              " 'due',\n",
              " 'partly',\n",
              " 'to',\n",
              " 'a',\n",
              " 'flurry',\n",
              " 'of',\n",
              " 'results',\n",
              " 'showing',\n",
              " 'that',\n",
              " 'such',\n",
              " 'techniques',\n",
              " 'can',\n",
              " 'achieve',\n",
              " 'state',\n",
              " 'of',\n",
              " 'the',\n",
              " 'art',\n",
              " 'results',\n",
              " 'in',\n",
              " 'many',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'tasks',\n",
              " 'e',\n",
              " 'g',\n",
              " 'in',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'and',\n",
              " 'parsing',\n",
              " 'this',\n",
              " 'is',\n",
              " 'increasingly',\n",
              " 'important',\n",
              " 'in',\n",
              " 'medicine',\n",
              " 'and',\n",
              " 'healthcare',\n",
              " 'where',\n",
              " 'nlp',\n",
              " 'helps',\n",
              " 'analyze',\n",
              " 'notes',\n",
              " 'and',\n",
              " 'text',\n",
              " 'in',\n",
              " 'electronic',\n",
              " 'health',\n",
              " 'records',\n",
              " 'that',\n",
              " 'would',\n",
              " 'otherwise',\n",
              " 'be',\n",
              " 'inaccessible',\n",
              " 'for',\n",
              " 'study',\n",
              " 'when',\n",
              " 'seeking',\n",
              " 'to',\n",
              " 'improve',\n",
              " 'care',\n",
              " 'or',\n",
              " 'protect',\n",
              " 'patient',\n",
              " 'privacy',\n",
              " 'symbolic',\n",
              " 'approach',\n",
              " 'i',\n",
              " 'e',\n",
              " 'the',\n",
              " 'hand',\n",
              " 'coding',\n",
              " 'of',\n",
              " 'a',\n",
              " 'set',\n",
              " 'of',\n",
              " 'rules',\n",
              " 'for',\n",
              " 'manipulating',\n",
              " 'symbols',\n",
              " 'coupled',\n",
              " 'with',\n",
              " 'a',\n",
              " 'dictionary',\n",
              " 'lookup',\n",
              " 'was',\n",
              " 'historically',\n",
              " 'the',\n",
              " 'first',\n",
              " 'approach',\n",
              " 'used',\n",
              " 'both',\n",
              " 'by',\n",
              " 'ai',\n",
              " 'in',\n",
              " 'general',\n",
              " 'and',\n",
              " 'by',\n",
              " 'nlp',\n",
              " 'in',\n",
              " 'particular',\n",
              " 'such',\n",
              " 'as',\n",
              " 'by',\n",
              " 'writing',\n",
              " 'grammars',\n",
              " 'or',\n",
              " 'devising',\n",
              " 'heuristic',\n",
              " 'rules',\n",
              " 'for',\n",
              " 'stemming',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " 'which',\n",
              " 'include',\n",
              " 'both',\n",
              " 'statistical',\n",
              " 'and',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'on',\n",
              " 'the',\n",
              " 'other',\n",
              " 'hand',\n",
              " 'have',\n",
              " 'many',\n",
              " 'advantages',\n",
              " 'over',\n",
              " 'the',\n",
              " 'symbolic',\n",
              " 'approach',\n",
              " 'although',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'systems',\n",
              " 'for',\n",
              " 'manipulating',\n",
              " 'symbols',\n",
              " 'were',\n",
              " 'still',\n",
              " 'in',\n",
              " 'use',\n",
              " 'in',\n",
              " 'they',\n",
              " 'have',\n",
              " 'become',\n",
              " 'mostly',\n",
              " 'obsolete',\n",
              " 'with',\n",
              " 'the',\n",
              " 'advance',\n",
              " 'of',\n",
              " 'llms',\n",
              " 'in',\n",
              " 'before',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'commonly',\n",
              " 'used',\n",
              " 'in',\n",
              " 'the',\n",
              " 'late',\n",
              " 's',\n",
              " 'and',\n",
              " 'mid',\n",
              " 's',\n",
              " 'the',\n",
              " 'statistical',\n",
              " 'approach',\n",
              " 'ended',\n",
              " 'a',\n",
              " 'period',\n",
              " 'of',\n",
              " 'ai',\n",
              " 'winter',\n",
              " 'which',\n",
              " 'was',\n",
              " 'caused',\n",
              " 'by',\n",
              " 'the',\n",
              " 'inefficiencies',\n",
              " 'of',\n",
              " 'the',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approaches',\n",
              " 'the',\n",
              " 'earliest',\n",
              " 'decision',\n",
              " 'trees',\n",
              " 'producing',\n",
              " 'systems',\n",
              " 'of',\n",
              " 'hard',\n",
              " 'if',\n",
              " 'then',\n",
              " 'rules',\n",
              " 'were',\n",
              " 'still',\n",
              " 'very',\n",
              " 'similar',\n",
              " 'to',\n",
              " 'the',\n",
              " 'old',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approaches',\n",
              " 'only',\n",
              " 'the',\n",
              " 'introduction',\n",
              " 'of',\n",
              " 'hidden',\n",
              " 'markov',\n",
              " 'models',\n",
              " 'applied',\n",
              " 'to',\n",
              " 'part',\n",
              " 'of',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " 'announced',\n",
              " 'the',\n",
              " 'end',\n",
              " 'of',\n",
              " 'the',\n",
              " 'old',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approach',\n",
              " 'a',\n",
              " 'major',\n",
              " 'drawback',\n",
              " 'of',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'is',\n",
              " 'that',\n",
              " 'they',\n",
              " 'require',\n",
              " 'elaborate',\n",
              " 'feature',\n",
              " 'engineering',\n",
              " 'since',\n",
              " 'the',\n",
              " 'statistical',\n",
              " 'approach',\n",
              " 'was',\n",
              " 'replaced',\n",
              " 'by',\n",
              " 'the',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'approach',\n",
              " 'using',\n",
              " 'word',\n",
              " 'embeddings',\n",
              " 'to',\n",
              " 'capture',\n",
              " 'semantic',\n",
              " 'properties',\n",
              " 'of',\n",
              " 'words',\n",
              " 'intermediate',\n",
              " 'tasks',\n",
              " 'e',\n",
              " 'g',\n",
              " 'part',\n",
              " 'of',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " 'and',\n",
              " 'dependency',\n",
              " 'parsing',\n",
              " 'have',\n",
              " 'not',\n",
              " 'been',\n",
              " 'needed',\n",
              " 'anymore',\n",
              " 'neural',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'based',\n",
              " 'on',\n",
              " 'then',\n",
              " 'newly',\n",
              " 'invented',\n",
              " 'sequence',\n",
              " 'to',\n",
              " 'sequence',\n",
              " 'transformations',\n",
              " 'made',\n",
              " 'obsolete',\n",
              " 'the',\n",
              " 'intermediate',\n",
              " 'steps',\n",
              " 'such',\n",
              " 'as',\n",
              " 'word',\n",
              " 'alignment',\n",
              " 'previously',\n",
              " 'necessary',\n",
              " 'for',\n",
              " 'statistical',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'the',\n",
              " 'following',\n",
              " 'is',\n",
              " 'a',\n",
              " 'list',\n",
              " 'of',\n",
              " 'some',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'commonly',\n",
              " 'researched',\n",
              " 'tasks',\n",
              " 'in',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'some',\n",
              " 'of',\n",
              " 'these',\n",
              " 'tasks',\n",
              " 'have',\n",
              " 'direct',\n",
              " 'real',\n",
              " 'world',\n",
              " 'applications',\n",
              " 'while',\n",
              " 'others',\n",
              " 'more',\n",
              " 'commonly',\n",
              " 'serve',\n",
              " 'as',\n",
              " 'subtasks',\n",
              " 'that',\n",
              " 'are',\n",
              " 'used',\n",
              " 'to',\n",
              " 'aid',\n",
              " 'in',\n",
              " 'solving',\n",
              " 'larger',\n",
              " 'tasks',\n",
              " 'though',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'are',\n",
              " 'closely',\n",
              " 'intertwined',\n",
              " 'they',\n",
              " 'can',\n",
              " 'be',\n",
              " 'subdivided',\n",
              " 'into',\n",
              " 'categories',\n",
              " 'for',\n",
              " 'convenience',\n",
              " 'a',\n",
              " 'coarse',\n",
              " 'division',\n",
              " 'is',\n",
              " 'given',\n",
              " 'below',\n",
              " 'based',\n",
              " 'on',\n",
              " 'long',\n",
              " 'standing',\n",
              " 'trends',\n",
              " 'in',\n",
              " 'the',\n",
              " 'field',\n",
              " 'it',\n",
              " 'is',\n",
              " 'possible',\n",
              " 'to',\n",
              " 'extrapolate',\n",
              " 'future',\n",
              " 'directions',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'as',\n",
              " 'of',\n",
              " 'three',\n",
              " 'trends',\n",
              " 'among',\n",
              " 'the',\n",
              " 'topics',\n",
              " 'of',\n",
              " 'the',\n",
              " 'long',\n",
              " 'standing',\n",
              " 'series',\n",
              " 'of',\n",
              " 'conll',\n",
              " 'shared',\n",
              " 'tasks',\n",
              " 'can',\n",
              " 'be',\n",
              " 'observed',\n",
              " 'most',\n",
              " 'higher',\n",
              " 'level',\n",
              " 'nlp',\n",
              " 'applications',\n",
              " 'involve',\n",
              " 'aspects',\n",
              " 'that',\n",
              " 'emulate',\n",
              " 'intelligent',\n",
              " 'behaviour',\n",
              " 'and',\n",
              " 'apparent',\n",
              " 'comprehension',\n",
              " 'of',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'more',\n",
              " 'broadly',\n",
              " 'speaking',\n",
              " 'the',\n",
              " 'technical',\n",
              " 'operationalization',\n",
              " 'of',\n",
              " 'increasingly',\n",
              " 'advanced',\n",
              " 'aspects',\n",
              " 'of',\n",
              " 'cognitive',\n",
              " 'behaviour',\n",
              " 'represents',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'developmental',\n",
              " 'trajectories',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'see',\n",
              " 'trends',\n",
              " 'among',\n",
              " 'conll',\n",
              " 'shared',\n",
              " 'tasks',\n",
              " 'above',\n",
              " 'cognition',\n",
              " 'refers',\n",
              " 'to',\n",
              " 'the',\n",
              " 'mental',\n",
              " 'action',\n",
              " 'or',\n",
              " 'process',\n",
              " 'of',\n",
              " 'acquiring',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'understanding',\n",
              " 'through',\n",
              " 'thought',\n",
              " 'experience',\n",
              " 'and',\n",
              " 'the',\n",
              " 'senses',\n",
              " 'cognitive',\n",
              " 'science',\n",
              " 'is',\n",
              " 'the',\n",
              " 'interdisciplinary',\n",
              " 'scientific',\n",
              " 'study',\n",
              " 'of',\n",
              " 'the',\n",
              " 'mind',\n",
              " 'and',\n",
              " 'its',\n",
              " 'processes',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'is',\n",
              " 'an',\n",
              " 'interdisciplinary',\n",
              " 'branch',\n",
              " 'of',\n",
              " 'linguistics',\n",
              " 'combining',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'research',\n",
              " 'from',\n",
              " 'both',\n",
              " 'psychology',\n",
              " 'and',\n",
              " 'linguistics',\n",
              " 'especially',\n",
              " 'during',\n",
              " 'the',\n",
              " 'age',\n",
              " 'of',\n",
              " 'symbolic',\n",
              " 'nlp',\n",
              " 'the',\n",
              " 'area',\n",
              " 'of',\n",
              " 'computational',\n",
              " 'linguistics',\n",
              " 'maintained',\n",
              " 'strong',\n",
              " 'ties',\n",
              " 'with',\n",
              " 'cognitive',\n",
              " 'studies',\n",
              " 'as',\n",
              " 'an',\n",
              " 'example',\n",
              " 'george',\n",
              " 'lakoff',\n",
              " 'offers',\n",
              " 'a',\n",
              " 'methodology',\n",
              " 'to',\n",
              " 'build',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'nlp',\n",
              " 'algorithms',\n",
              " 'through',\n",
              " 'the',\n",
              " 'perspective',\n",
              " 'of',\n",
              " 'cognitive',\n",
              " 'science',\n",
              " 'along',\n",
              " 'with',\n",
              " 'the',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Número de palabras: {len(palabras)}')"
      ],
      "metadata": {
        "id": "dJ-AFakkm478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2eb504-da2b-47a0-9aa6-66a451f86e36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de palabras: 1166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que ya tenemos las palabras extraidas, podemos hacer un poco más de limpieza, eliminando las stop-words, como ya sabemos:"
      ],
      "metadata": {
        "id": "f41MxV1XmpeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "palabras = [p for p in palabras if p not in stopwords.words('english')]\n",
        "palabras"
      ],
      "metadata": {
        "id": "p5BAEZbijw1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364f21d3-a1b3-4132-fa08-23e36115d90b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'nlp',\n",
              " 'interdisciplinary',\n",
              " 'subfield',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'information',\n",
              " 'retrieval',\n",
              " 'primarily',\n",
              " 'concerned',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'ability',\n",
              " 'support',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " 'involves',\n",
              " 'processing',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'datasets',\n",
              " 'text',\n",
              " 'corpora',\n",
              " 'speech',\n",
              " 'corpora',\n",
              " 'using',\n",
              " 'either',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'probabilistic',\n",
              " 'e',\n",
              " 'statistical',\n",
              " 'recently',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'based',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " 'goal',\n",
              " 'computer',\n",
              " 'capable',\n",
              " 'understanding',\n",
              " 'citation',\n",
              " 'needed',\n",
              " 'contents',\n",
              " 'documents',\n",
              " 'including',\n",
              " 'contextual',\n",
              " 'nuances',\n",
              " 'language',\n",
              " 'within',\n",
              " 'end',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'often',\n",
              " 'borrows',\n",
              " 'ideas',\n",
              " 'theoretical',\n",
              " 'linguistics',\n",
              " 'technology',\n",
              " 'accurately',\n",
              " 'extract',\n",
              " 'information',\n",
              " 'insights',\n",
              " 'contained',\n",
              " 'documents',\n",
              " 'well',\n",
              " 'categorize',\n",
              " 'organize',\n",
              " 'documents',\n",
              " 'challenges',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'frequently',\n",
              " 'involve',\n",
              " 'speech',\n",
              " 'recognition',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'generation',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'roots',\n",
              " 'already',\n",
              " 'alan',\n",
              " 'turing',\n",
              " 'published',\n",
              " 'article',\n",
              " 'titled',\n",
              " 'computing',\n",
              " 'machinery',\n",
              " 'intelligence',\n",
              " 'proposed',\n",
              " 'called',\n",
              " 'turing',\n",
              " 'test',\n",
              " 'criterion',\n",
              " 'intelligence',\n",
              " 'though',\n",
              " 'time',\n",
              " 'articulated',\n",
              " 'problem',\n",
              " 'separate',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'proposed',\n",
              " 'test',\n",
              " 'includes',\n",
              " 'task',\n",
              " 'involves',\n",
              " 'automated',\n",
              " 'interpretation',\n",
              " 'generation',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'premise',\n",
              " 'symbolic',\n",
              " 'nlp',\n",
              " 'well',\n",
              " 'summarized',\n",
              " 'john',\n",
              " 'searle',\n",
              " 'chinese',\n",
              " 'room',\n",
              " 'experiment',\n",
              " 'given',\n",
              " 'collection',\n",
              " 'rules',\n",
              " 'e',\n",
              " 'g',\n",
              " 'chinese',\n",
              " 'phrasebook',\n",
              " 'questions',\n",
              " 'matching',\n",
              " 'answers',\n",
              " 'computer',\n",
              " 'emulates',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " 'nlp',\n",
              " 'tasks',\n",
              " 'applying',\n",
              " 'rules',\n",
              " 'data',\n",
              " 'confronts',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'systems',\n",
              " 'based',\n",
              " 'complex',\n",
              " 'sets',\n",
              " 'hand',\n",
              " 'written',\n",
              " 'rules',\n",
              " 'starting',\n",
              " 'late',\n",
              " 'however',\n",
              " 'revolution',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'introduction',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'algorithms',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'due',\n",
              " 'steady',\n",
              " 'increase',\n",
              " 'computational',\n",
              " 'power',\n",
              " 'see',\n",
              " 'moore',\n",
              " 'law',\n",
              " 'gradual',\n",
              " 'lessening',\n",
              " 'dominance',\n",
              " 'chomskyan',\n",
              " 'theories',\n",
              " 'linguistics',\n",
              " 'e',\n",
              " 'g',\n",
              " 'transformational',\n",
              " 'grammar',\n",
              " 'whose',\n",
              " 'theoretical',\n",
              " 'underpinnings',\n",
              " 'discouraged',\n",
              " 'sort',\n",
              " 'corpus',\n",
              " 'linguistics',\n",
              " 'underlies',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approach',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'word',\n",
              " 'n',\n",
              " 'gram',\n",
              " 'model',\n",
              " 'time',\n",
              " 'best',\n",
              " 'statistical',\n",
              " 'algorithm',\n",
              " 'overperformed',\n",
              " 'multi',\n",
              " 'layer',\n",
              " 'perceptron',\n",
              " 'single',\n",
              " 'hidden',\n",
              " 'layer',\n",
              " 'context',\n",
              " 'length',\n",
              " 'several',\n",
              " 'words',\n",
              " 'trained',\n",
              " 'million',\n",
              " 'words',\n",
              " 'cpu',\n",
              " 'cluster',\n",
              " 'language',\n",
              " 'modelling',\n",
              " 'yoshua',\n",
              " 'bengio',\n",
              " 'co',\n",
              " 'authors',\n",
              " 'tom',\n",
              " 'mikolov',\n",
              " 'phd',\n",
              " 'student',\n",
              " 'brno',\n",
              " 'university',\n",
              " 'technology',\n",
              " 'co',\n",
              " 'authors',\n",
              " 'applied',\n",
              " 'simple',\n",
              " 'recurrent',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'single',\n",
              " 'hidden',\n",
              " 'layer',\n",
              " 'language',\n",
              " 'modelling',\n",
              " 'following',\n",
              " 'years',\n",
              " 'went',\n",
              " 'develop',\n",
              " 'word',\n",
              " 'vec',\n",
              " 'representation',\n",
              " 'learning',\n",
              " 'deep',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'style',\n",
              " 'featuring',\n",
              " 'many',\n",
              " 'hidden',\n",
              " 'layers',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'methods',\n",
              " 'became',\n",
              " 'widespread',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'popularity',\n",
              " 'due',\n",
              " 'partly',\n",
              " 'flurry',\n",
              " 'results',\n",
              " 'showing',\n",
              " 'techniques',\n",
              " 'achieve',\n",
              " 'state',\n",
              " 'art',\n",
              " 'results',\n",
              " 'many',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'tasks',\n",
              " 'e',\n",
              " 'g',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'parsing',\n",
              " 'increasingly',\n",
              " 'important',\n",
              " 'medicine',\n",
              " 'healthcare',\n",
              " 'nlp',\n",
              " 'helps',\n",
              " 'analyze',\n",
              " 'notes',\n",
              " 'text',\n",
              " 'electronic',\n",
              " 'health',\n",
              " 'records',\n",
              " 'would',\n",
              " 'otherwise',\n",
              " 'inaccessible',\n",
              " 'study',\n",
              " 'seeking',\n",
              " 'improve',\n",
              " 'care',\n",
              " 'protect',\n",
              " 'patient',\n",
              " 'privacy',\n",
              " 'symbolic',\n",
              " 'approach',\n",
              " 'e',\n",
              " 'hand',\n",
              " 'coding',\n",
              " 'set',\n",
              " 'rules',\n",
              " 'manipulating',\n",
              " 'symbols',\n",
              " 'coupled',\n",
              " 'dictionary',\n",
              " 'lookup',\n",
              " 'historically',\n",
              " 'first',\n",
              " 'approach',\n",
              " 'used',\n",
              " 'ai',\n",
              " 'general',\n",
              " 'nlp',\n",
              " 'particular',\n",
              " 'writing',\n",
              " 'grammars',\n",
              " 'devising',\n",
              " 'heuristic',\n",
              " 'rules',\n",
              " 'stemming',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " 'include',\n",
              " 'statistical',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'hand',\n",
              " 'many',\n",
              " 'advantages',\n",
              " 'symbolic',\n",
              " 'approach',\n",
              " 'although',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'systems',\n",
              " 'manipulating',\n",
              " 'symbols',\n",
              " 'still',\n",
              " 'use',\n",
              " 'become',\n",
              " 'mostly',\n",
              " 'obsolete',\n",
              " 'advance',\n",
              " 'llms',\n",
              " 'commonly',\n",
              " 'used',\n",
              " 'late',\n",
              " 'mid',\n",
              " 'statistical',\n",
              " 'approach',\n",
              " 'ended',\n",
              " 'period',\n",
              " 'ai',\n",
              " 'winter',\n",
              " 'caused',\n",
              " 'inefficiencies',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approaches',\n",
              " 'earliest',\n",
              " 'decision',\n",
              " 'trees',\n",
              " 'producing',\n",
              " 'systems',\n",
              " 'hard',\n",
              " 'rules',\n",
              " 'still',\n",
              " 'similar',\n",
              " 'old',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approaches',\n",
              " 'introduction',\n",
              " 'hidden',\n",
              " 'markov',\n",
              " 'models',\n",
              " 'applied',\n",
              " 'part',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " 'announced',\n",
              " 'end',\n",
              " 'old',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approach',\n",
              " 'major',\n",
              " 'drawback',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'require',\n",
              " 'elaborate',\n",
              " 'feature',\n",
              " 'engineering',\n",
              " 'since',\n",
              " 'statistical',\n",
              " 'approach',\n",
              " 'replaced',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'approach',\n",
              " 'using',\n",
              " 'word',\n",
              " 'embeddings',\n",
              " 'capture',\n",
              " 'semantic',\n",
              " 'properties',\n",
              " 'words',\n",
              " 'intermediate',\n",
              " 'tasks',\n",
              " 'e',\n",
              " 'g',\n",
              " 'part',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " 'dependency',\n",
              " 'parsing',\n",
              " 'needed',\n",
              " 'anymore',\n",
              " 'neural',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'based',\n",
              " 'newly',\n",
              " 'invented',\n",
              " 'sequence',\n",
              " 'sequence',\n",
              " 'transformations',\n",
              " 'made',\n",
              " 'obsolete',\n",
              " 'intermediate',\n",
              " 'steps',\n",
              " 'word',\n",
              " 'alignment',\n",
              " 'previously',\n",
              " 'necessary',\n",
              " 'statistical',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'following',\n",
              " 'list',\n",
              " 'commonly',\n",
              " 'researched',\n",
              " 'tasks',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'direct',\n",
              " 'real',\n",
              " 'world',\n",
              " 'applications',\n",
              " 'others',\n",
              " 'commonly',\n",
              " 'serve',\n",
              " 'subtasks',\n",
              " 'used',\n",
              " 'aid',\n",
              " 'solving',\n",
              " 'larger',\n",
              " 'tasks',\n",
              " 'though',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'closely',\n",
              " 'intertwined',\n",
              " 'subdivided',\n",
              " 'categories',\n",
              " 'convenience',\n",
              " 'coarse',\n",
              " 'division',\n",
              " 'given',\n",
              " 'based',\n",
              " 'long',\n",
              " 'standing',\n",
              " 'trends',\n",
              " 'field',\n",
              " 'possible',\n",
              " 'extrapolate',\n",
              " 'future',\n",
              " 'directions',\n",
              " 'nlp',\n",
              " 'three',\n",
              " 'trends',\n",
              " 'among',\n",
              " 'topics',\n",
              " 'long',\n",
              " 'standing',\n",
              " 'series',\n",
              " 'conll',\n",
              " 'shared',\n",
              " 'tasks',\n",
              " 'observed',\n",
              " 'higher',\n",
              " 'level',\n",
              " 'nlp',\n",
              " 'applications',\n",
              " 'involve',\n",
              " 'aspects',\n",
              " 'emulate',\n",
              " 'intelligent',\n",
              " 'behaviour',\n",
              " 'apparent',\n",
              " 'comprehension',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'broadly',\n",
              " 'speaking',\n",
              " 'technical',\n",
              " 'operationalization',\n",
              " 'increasingly',\n",
              " 'advanced',\n",
              " 'aspects',\n",
              " 'cognitive',\n",
              " 'behaviour',\n",
              " 'represents',\n",
              " 'one',\n",
              " 'developmental',\n",
              " 'trajectories',\n",
              " 'nlp',\n",
              " 'see',\n",
              " 'trends',\n",
              " 'among',\n",
              " 'conll',\n",
              " 'shared',\n",
              " 'tasks',\n",
              " 'cognition',\n",
              " 'refers',\n",
              " 'mental',\n",
              " 'action',\n",
              " 'process',\n",
              " 'acquiring',\n",
              " 'knowledge',\n",
              " 'understanding',\n",
              " 'thought',\n",
              " 'experience',\n",
              " 'senses',\n",
              " 'cognitive',\n",
              " 'science',\n",
              " 'interdisciplinary',\n",
              " 'scientific',\n",
              " 'study',\n",
              " 'mind',\n",
              " 'processes',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'interdisciplinary',\n",
              " 'branch',\n",
              " 'linguistics',\n",
              " 'combining',\n",
              " 'knowledge',\n",
              " 'research',\n",
              " 'psychology',\n",
              " 'linguistics',\n",
              " 'especially',\n",
              " 'age',\n",
              " 'symbolic',\n",
              " 'nlp',\n",
              " 'area',\n",
              " 'computational',\n",
              " 'linguistics',\n",
              " 'maintained',\n",
              " 'strong',\n",
              " 'ties',\n",
              " 'cognitive',\n",
              " 'studies',\n",
              " 'example',\n",
              " 'george',\n",
              " 'lakoff',\n",
              " 'offers',\n",
              " 'methodology',\n",
              " 'build',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'nlp',\n",
              " 'algorithms',\n",
              " 'perspective',\n",
              " 'cognitive',\n",
              " 'science',\n",
              " 'along',\n",
              " 'findings',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'two',\n",
              " 'defining',\n",
              " 'aspects',\n",
              " 'ties',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'part',\n",
              " 'historical',\n",
              " 'heritage',\n",
              " 'nlp',\n",
              " 'less',\n",
              " 'frequently',\n",
              " 'addressed',\n",
              " 'since',\n",
              " 'statistical',\n",
              " 'turn',\n",
              " 'nevertheless',\n",
              " 'approaches',\n",
              " 'develop',\n",
              " 'cognitive',\n",
              " 'models',\n",
              " 'towards',\n",
              " 'technically',\n",
              " 'operationalizable',\n",
              " 'frameworks',\n",
              " 'pursued',\n",
              " 'context',\n",
              " 'various',\n",
              " 'frameworks',\n",
              " 'e',\n",
              " 'g',\n",
              " 'cognitive',\n",
              " 'grammar',\n",
              " 'functional',\n",
              " 'grammar',\n",
              " 'construction',\n",
              " 'grammar',\n",
              " 'computational',\n",
              " 'psycholinguistics',\n",
              " 'cognitive',\n",
              " 'neuroscience',\n",
              " 'e',\n",
              " 'g',\n",
              " 'act',\n",
              " 'r',\n",
              " 'however',\n",
              " 'limited',\n",
              " 'uptake',\n",
              " 'mainstream',\n",
              " 'nlp',\n",
              " 'measured',\n",
              " 'presence',\n",
              " 'major',\n",
              " 'conferences',\n",
              " 'acl',\n",
              " 'recently',\n",
              " 'ideas',\n",
              " 'cognitive',\n",
              " 'nlp',\n",
              " 'revived',\n",
              " 'approach',\n",
              " 'achieve',\n",
              " 'explainability',\n",
              " 'e',\n",
              " 'g',\n",
              " 'notion',\n",
              " 'cognitive',\n",
              " 'ai',\n",
              " 'likewise',\n",
              " 'ideas',\n",
              " 'cognitive',\n",
              " 'nlp',\n",
              " 'inherent',\n",
              " 'neural',\n",
              " 'models',\n",
              " 'multimodal',\n",
              " 'nlp',\n",
              " 'although',\n",
              " 'rarely',\n",
              " 'made',\n",
              " 'explicit',\n",
              " 'developments',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'specifically',\n",
              " 'tools',\n",
              " 'technologies',\n",
              " 'using',\n",
              " 'large',\n",
              " 'language',\n",
              " 'model',\n",
              " 'approaches',\n",
              " 'new',\n",
              " 'directions',\n",
              " 'artificial',\n",
              " 'general',\n",
              " 'intelligence',\n",
              " 'based',\n",
              " 'free',\n",
              " 'energy',\n",
              " 'principle',\n",
              " 'british',\n",
              " 'neuroscientist',\n",
              " 'theoretician',\n",
              " 'university',\n",
              " 'college',\n",
              " 'london',\n",
              " 'karl',\n",
              " 'j',\n",
              " 'friston']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Número de palabras: {len(palabras)}')"
      ],
      "metadata": {
        "id": "H24URUY-jE7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecac153b-03b5-4e01-d509-70c22388c9dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de palabras: 728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fijaos cómo hemos conseguido limpiar bastante el dataset, quitando practicamente 500 palabras que no aportan información (las stop-words).\n",
        "\n",
        "Sin embargo, si os fijáis, siguen habiendo cosas que no debería haber, como por ejemplo letras sueltas.\n",
        "\n",
        "Vamos a inspeccionar un poco:"
      ],
      "metadata": {
        "id": "gEjFqSEQnAZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in palabras:\n",
        "    if len(p) < 3:\n",
        "        print(p)"
      ],
      "metadata": {
        "id": "a3kPv7krnN56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11a8fb5-e7f2-4a15-d9ba-329184e87582"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e\n",
            "e\n",
            "g\n",
            "e\n",
            "g\n",
            "n\n",
            "co\n",
            "co\n",
            "e\n",
            "g\n",
            "e\n",
            "ai\n",
            "ai\n",
            "e\n",
            "g\n",
            "e\n",
            "g\n",
            "e\n",
            "g\n",
            "r\n",
            "e\n",
            "g\n",
            "ai\n",
            "j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, tenemos \"palabras\" que son solo las letras \"e\", \"g\" y \"r\", y además \"ai\". Lógicamente \"AI\" es una palabra y no deberíamos eliminarla (las siglas de Artificial Intelligence), pero las demás si podemos quitarlas:"
      ],
      "metadata": {
        "id": "ZqWYdW9InVHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras = [p for p in palabras if p not in ['e', 'g', 'r', 'n', 'co', 'j']]\n",
        "palabras"
      ],
      "metadata": {
        "id": "SuFV7Fp_ng2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7379a8d6-f7ca-4540-a230-dbe278a1536f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'nlp',\n",
              " 'interdisciplinary',\n",
              " 'subfield',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'information',\n",
              " 'retrieval',\n",
              " 'primarily',\n",
              " 'concerned',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'ability',\n",
              " 'support',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " 'involves',\n",
              " 'processing',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'datasets',\n",
              " 'text',\n",
              " 'corpora',\n",
              " 'speech',\n",
              " 'corpora',\n",
              " 'using',\n",
              " 'either',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'probabilistic',\n",
              " 'statistical',\n",
              " 'recently',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'based',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " 'goal',\n",
              " 'computer',\n",
              " 'capable',\n",
              " 'understanding',\n",
              " 'citation',\n",
              " 'needed',\n",
              " 'contents',\n",
              " 'documents',\n",
              " 'including',\n",
              " 'contextual',\n",
              " 'nuances',\n",
              " 'language',\n",
              " 'within',\n",
              " 'end',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'often',\n",
              " 'borrows',\n",
              " 'ideas',\n",
              " 'theoretical',\n",
              " 'linguistics',\n",
              " 'technology',\n",
              " 'accurately',\n",
              " 'extract',\n",
              " 'information',\n",
              " 'insights',\n",
              " 'contained',\n",
              " 'documents',\n",
              " 'well',\n",
              " 'categorize',\n",
              " 'organize',\n",
              " 'documents',\n",
              " 'challenges',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'frequently',\n",
              " 'involve',\n",
              " 'speech',\n",
              " 'recognition',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'generation',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'roots',\n",
              " 'already',\n",
              " 'alan',\n",
              " 'turing',\n",
              " 'published',\n",
              " 'article',\n",
              " 'titled',\n",
              " 'computing',\n",
              " 'machinery',\n",
              " 'intelligence',\n",
              " 'proposed',\n",
              " 'called',\n",
              " 'turing',\n",
              " 'test',\n",
              " 'criterion',\n",
              " 'intelligence',\n",
              " 'though',\n",
              " 'time',\n",
              " 'articulated',\n",
              " 'problem',\n",
              " 'separate',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'proposed',\n",
              " 'test',\n",
              " 'includes',\n",
              " 'task',\n",
              " 'involves',\n",
              " 'automated',\n",
              " 'interpretation',\n",
              " 'generation',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'premise',\n",
              " 'symbolic',\n",
              " 'nlp',\n",
              " 'well',\n",
              " 'summarized',\n",
              " 'john',\n",
              " 'searle',\n",
              " 'chinese',\n",
              " 'room',\n",
              " 'experiment',\n",
              " 'given',\n",
              " 'collection',\n",
              " 'rules',\n",
              " 'chinese',\n",
              " 'phrasebook',\n",
              " 'questions',\n",
              " 'matching',\n",
              " 'answers',\n",
              " 'computer',\n",
              " 'emulates',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " 'nlp',\n",
              " 'tasks',\n",
              " 'applying',\n",
              " 'rules',\n",
              " 'data',\n",
              " 'confronts',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'systems',\n",
              " 'based',\n",
              " 'complex',\n",
              " 'sets',\n",
              " 'hand',\n",
              " 'written',\n",
              " 'rules',\n",
              " 'starting',\n",
              " 'late',\n",
              " 'however',\n",
              " 'revolution',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'introduction',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'algorithms',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'due',\n",
              " 'steady',\n",
              " 'increase',\n",
              " 'computational',\n",
              " 'power',\n",
              " 'see',\n",
              " 'moore',\n",
              " 'law',\n",
              " 'gradual',\n",
              " 'lessening',\n",
              " 'dominance',\n",
              " 'chomskyan',\n",
              " 'theories',\n",
              " 'linguistics',\n",
              " 'transformational',\n",
              " 'grammar',\n",
              " 'whose',\n",
              " 'theoretical',\n",
              " 'underpinnings',\n",
              " 'discouraged',\n",
              " 'sort',\n",
              " 'corpus',\n",
              " 'linguistics',\n",
              " 'underlies',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approach',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'word',\n",
              " 'gram',\n",
              " 'model',\n",
              " 'time',\n",
              " 'best',\n",
              " 'statistical',\n",
              " 'algorithm',\n",
              " 'overperformed',\n",
              " 'multi',\n",
              " 'layer',\n",
              " 'perceptron',\n",
              " 'single',\n",
              " 'hidden',\n",
              " 'layer',\n",
              " 'context',\n",
              " 'length',\n",
              " 'several',\n",
              " 'words',\n",
              " 'trained',\n",
              " 'million',\n",
              " 'words',\n",
              " 'cpu',\n",
              " 'cluster',\n",
              " 'language',\n",
              " 'modelling',\n",
              " 'yoshua',\n",
              " 'bengio',\n",
              " 'authors',\n",
              " 'tom',\n",
              " 'mikolov',\n",
              " 'phd',\n",
              " 'student',\n",
              " 'brno',\n",
              " 'university',\n",
              " 'technology',\n",
              " 'authors',\n",
              " 'applied',\n",
              " 'simple',\n",
              " 'recurrent',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'single',\n",
              " 'hidden',\n",
              " 'layer',\n",
              " 'language',\n",
              " 'modelling',\n",
              " 'following',\n",
              " 'years',\n",
              " 'went',\n",
              " 'develop',\n",
              " 'word',\n",
              " 'vec',\n",
              " 'representation',\n",
              " 'learning',\n",
              " 'deep',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'style',\n",
              " 'featuring',\n",
              " 'many',\n",
              " 'hidden',\n",
              " 'layers',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'methods',\n",
              " 'became',\n",
              " 'widespread',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'popularity',\n",
              " 'due',\n",
              " 'partly',\n",
              " 'flurry',\n",
              " 'results',\n",
              " 'showing',\n",
              " 'techniques',\n",
              " 'achieve',\n",
              " 'state',\n",
              " 'art',\n",
              " 'results',\n",
              " 'many',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'tasks',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'parsing',\n",
              " 'increasingly',\n",
              " 'important',\n",
              " 'medicine',\n",
              " 'healthcare',\n",
              " 'nlp',\n",
              " 'helps',\n",
              " 'analyze',\n",
              " 'notes',\n",
              " 'text',\n",
              " 'electronic',\n",
              " 'health',\n",
              " 'records',\n",
              " 'would',\n",
              " 'otherwise',\n",
              " 'inaccessible',\n",
              " 'study',\n",
              " 'seeking',\n",
              " 'improve',\n",
              " 'care',\n",
              " 'protect',\n",
              " 'patient',\n",
              " 'privacy',\n",
              " 'symbolic',\n",
              " 'approach',\n",
              " 'hand',\n",
              " 'coding',\n",
              " 'set',\n",
              " 'rules',\n",
              " 'manipulating',\n",
              " 'symbols',\n",
              " 'coupled',\n",
              " 'dictionary',\n",
              " 'lookup',\n",
              " 'historically',\n",
              " 'first',\n",
              " 'approach',\n",
              " 'used',\n",
              " 'ai',\n",
              " 'general',\n",
              " 'nlp',\n",
              " 'particular',\n",
              " 'writing',\n",
              " 'grammars',\n",
              " 'devising',\n",
              " 'heuristic',\n",
              " 'rules',\n",
              " 'stemming',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " 'include',\n",
              " 'statistical',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'hand',\n",
              " 'many',\n",
              " 'advantages',\n",
              " 'symbolic',\n",
              " 'approach',\n",
              " 'although',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'systems',\n",
              " 'manipulating',\n",
              " 'symbols',\n",
              " 'still',\n",
              " 'use',\n",
              " 'become',\n",
              " 'mostly',\n",
              " 'obsolete',\n",
              " 'advance',\n",
              " 'llms',\n",
              " 'commonly',\n",
              " 'used',\n",
              " 'late',\n",
              " 'mid',\n",
              " 'statistical',\n",
              " 'approach',\n",
              " 'ended',\n",
              " 'period',\n",
              " 'ai',\n",
              " 'winter',\n",
              " 'caused',\n",
              " 'inefficiencies',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approaches',\n",
              " 'earliest',\n",
              " 'decision',\n",
              " 'trees',\n",
              " 'producing',\n",
              " 'systems',\n",
              " 'hard',\n",
              " 'rules',\n",
              " 'still',\n",
              " 'similar',\n",
              " 'old',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approaches',\n",
              " 'introduction',\n",
              " 'hidden',\n",
              " 'markov',\n",
              " 'models',\n",
              " 'applied',\n",
              " 'part',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " 'announced',\n",
              " 'end',\n",
              " 'old',\n",
              " 'rule',\n",
              " 'based',\n",
              " 'approach',\n",
              " 'major',\n",
              " 'drawback',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'require',\n",
              " 'elaborate',\n",
              " 'feature',\n",
              " 'engineering',\n",
              " 'since',\n",
              " 'statistical',\n",
              " 'approach',\n",
              " 'replaced',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'approach',\n",
              " 'using',\n",
              " 'word',\n",
              " 'embeddings',\n",
              " 'capture',\n",
              " 'semantic',\n",
              " 'properties',\n",
              " 'words',\n",
              " 'intermediate',\n",
              " 'tasks',\n",
              " 'part',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " 'dependency',\n",
              " 'parsing',\n",
              " 'needed',\n",
              " 'anymore',\n",
              " 'neural',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'based',\n",
              " 'newly',\n",
              " 'invented',\n",
              " 'sequence',\n",
              " 'sequence',\n",
              " 'transformations',\n",
              " 'made',\n",
              " 'obsolete',\n",
              " 'intermediate',\n",
              " 'steps',\n",
              " 'word',\n",
              " 'alignment',\n",
              " 'previously',\n",
              " 'necessary',\n",
              " 'statistical',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'following',\n",
              " 'list',\n",
              " 'commonly',\n",
              " 'researched',\n",
              " 'tasks',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'direct',\n",
              " 'real',\n",
              " 'world',\n",
              " 'applications',\n",
              " 'others',\n",
              " 'commonly',\n",
              " 'serve',\n",
              " 'subtasks',\n",
              " 'used',\n",
              " 'aid',\n",
              " 'solving',\n",
              " 'larger',\n",
              " 'tasks',\n",
              " 'though',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'closely',\n",
              " 'intertwined',\n",
              " 'subdivided',\n",
              " 'categories',\n",
              " 'convenience',\n",
              " 'coarse',\n",
              " 'division',\n",
              " 'given',\n",
              " 'based',\n",
              " 'long',\n",
              " 'standing',\n",
              " 'trends',\n",
              " 'field',\n",
              " 'possible',\n",
              " 'extrapolate',\n",
              " 'future',\n",
              " 'directions',\n",
              " 'nlp',\n",
              " 'three',\n",
              " 'trends',\n",
              " 'among',\n",
              " 'topics',\n",
              " 'long',\n",
              " 'standing',\n",
              " 'series',\n",
              " 'conll',\n",
              " 'shared',\n",
              " 'tasks',\n",
              " 'observed',\n",
              " 'higher',\n",
              " 'level',\n",
              " 'nlp',\n",
              " 'applications',\n",
              " 'involve',\n",
              " 'aspects',\n",
              " 'emulate',\n",
              " 'intelligent',\n",
              " 'behaviour',\n",
              " 'apparent',\n",
              " 'comprehension',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'broadly',\n",
              " 'speaking',\n",
              " 'technical',\n",
              " 'operationalization',\n",
              " 'increasingly',\n",
              " 'advanced',\n",
              " 'aspects',\n",
              " 'cognitive',\n",
              " 'behaviour',\n",
              " 'represents',\n",
              " 'one',\n",
              " 'developmental',\n",
              " 'trajectories',\n",
              " 'nlp',\n",
              " 'see',\n",
              " 'trends',\n",
              " 'among',\n",
              " 'conll',\n",
              " 'shared',\n",
              " 'tasks',\n",
              " 'cognition',\n",
              " 'refers',\n",
              " 'mental',\n",
              " 'action',\n",
              " 'process',\n",
              " 'acquiring',\n",
              " 'knowledge',\n",
              " 'understanding',\n",
              " 'thought',\n",
              " 'experience',\n",
              " 'senses',\n",
              " 'cognitive',\n",
              " 'science',\n",
              " 'interdisciplinary',\n",
              " 'scientific',\n",
              " 'study',\n",
              " 'mind',\n",
              " 'processes',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'interdisciplinary',\n",
              " 'branch',\n",
              " 'linguistics',\n",
              " 'combining',\n",
              " 'knowledge',\n",
              " 'research',\n",
              " 'psychology',\n",
              " 'linguistics',\n",
              " 'especially',\n",
              " 'age',\n",
              " 'symbolic',\n",
              " 'nlp',\n",
              " 'area',\n",
              " 'computational',\n",
              " 'linguistics',\n",
              " 'maintained',\n",
              " 'strong',\n",
              " 'ties',\n",
              " 'cognitive',\n",
              " 'studies',\n",
              " 'example',\n",
              " 'george',\n",
              " 'lakoff',\n",
              " 'offers',\n",
              " 'methodology',\n",
              " 'build',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'nlp',\n",
              " 'algorithms',\n",
              " 'perspective',\n",
              " 'cognitive',\n",
              " 'science',\n",
              " 'along',\n",
              " 'findings',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'two',\n",
              " 'defining',\n",
              " 'aspects',\n",
              " 'ties',\n",
              " 'cognitive',\n",
              " 'linguistics',\n",
              " 'part',\n",
              " 'historical',\n",
              " 'heritage',\n",
              " 'nlp',\n",
              " 'less',\n",
              " 'frequently',\n",
              " 'addressed',\n",
              " 'since',\n",
              " 'statistical',\n",
              " 'turn',\n",
              " 'nevertheless',\n",
              " 'approaches',\n",
              " 'develop',\n",
              " 'cognitive',\n",
              " 'models',\n",
              " 'towards',\n",
              " 'technically',\n",
              " 'operationalizable',\n",
              " 'frameworks',\n",
              " 'pursued',\n",
              " 'context',\n",
              " 'various',\n",
              " 'frameworks',\n",
              " 'cognitive',\n",
              " 'grammar',\n",
              " 'functional',\n",
              " 'grammar',\n",
              " 'construction',\n",
              " 'grammar',\n",
              " 'computational',\n",
              " 'psycholinguistics',\n",
              " 'cognitive',\n",
              " 'neuroscience',\n",
              " 'act',\n",
              " 'however',\n",
              " 'limited',\n",
              " 'uptake',\n",
              " 'mainstream',\n",
              " 'nlp',\n",
              " 'measured',\n",
              " 'presence',\n",
              " 'major',\n",
              " 'conferences',\n",
              " 'acl',\n",
              " 'recently',\n",
              " 'ideas',\n",
              " 'cognitive',\n",
              " 'nlp',\n",
              " 'revived',\n",
              " 'approach',\n",
              " 'achieve',\n",
              " 'explainability',\n",
              " 'notion',\n",
              " 'cognitive',\n",
              " 'ai',\n",
              " 'likewise',\n",
              " 'ideas',\n",
              " 'cognitive',\n",
              " 'nlp',\n",
              " 'inherent',\n",
              " 'neural',\n",
              " 'models',\n",
              " 'multimodal',\n",
              " 'nlp',\n",
              " 'although',\n",
              " 'rarely',\n",
              " 'made',\n",
              " 'explicit',\n",
              " 'developments',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'specifically',\n",
              " 'tools',\n",
              " 'technologies',\n",
              " 'using',\n",
              " 'large',\n",
              " 'language',\n",
              " 'model',\n",
              " 'approaches',\n",
              " 'new',\n",
              " 'directions',\n",
              " 'artificial',\n",
              " 'general',\n",
              " 'intelligence',\n",
              " 'based',\n",
              " 'free',\n",
              " 'energy',\n",
              " 'principle',\n",
              " 'british',\n",
              " 'neuroscientist',\n",
              " 'theoretician',\n",
              " 'university',\n",
              " 'college',\n",
              " 'london',\n",
              " 'karl',\n",
              " 'friston']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parece que ya no están presentes, pero vamos a asegurarnos:"
      ],
      "metadata": {
        "id": "uTHozZRjnq1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in palabras:\n",
        "    if len(p) < 3:\n",
        "        print(p)"
      ],
      "metadata": {
        "id": "CXLT-JMXnp4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc325eb-1035-45b0-d1d7-eb97befb6e20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ai\n",
            "ai\n",
            "ai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Perfecto! Pues ya podemos comenzar con el embedding Word2Vec. Para ello, podemos utilizar una librería llamada `gensim` que ya implementa este modelo y otros (más información en https://radimrehurek.com/gensim/).\n",
        "\n",
        "La importamos y creamos el objeto `Word2Vec` con las palabras que acabamos de limpiar.\n",
        "\n",
        "El parámetro `min_count` indica la frecuencia mínima que debe tener una palabra para que se incluya en el embedding. Esto quiere decir que si establecemos `min_count=2`, todas aquellas palabras que únicamente aparezcan una vez en nuestro texto, no se tendrán en cuenta en el embedding.\n",
        "\n",
        "Por otra parte, el primer argumento (`sentences`) debe ser una lista de oraciones. Nosotros, como las hemos juntado anteriormente (por facilitar el pre-procesamiento), tenemos solo una, así que tendremos que usar `[palabras]` como argumento. Si no, dará error, podéis comprobarlo :)\n",
        "\n",
        "¡Vamos al lio!"
      ],
      "metadata": {
        "id": "lBFU8_VtnuZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "word2vec = Word2Vec([palabras], min_count=2)"
      ],
      "metadata": {
        "id": "VprgoF2PjBdt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora ya podemos comprobar qué tal funciona nuestro embedding. De acuerdo a lo que hemos visto en clase, deberia de ser capaz de encontrar palabras similares y distintas.\n",
        "\n",
        "Pero antes, veamos realmente qué es lo que ha sucedido.\n",
        "\n",
        "Por ejemplo, veamos cuál es la representación de la palabra \"machine\":"
      ],
      "metadata": {
        "id": "GvZ66X42ofGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.wv['machine']"
      ],
      "metadata": {
        "id": "3fzlRQrckhBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f829b70-f2d6-41b3-eb6f-36d9785998c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.0237364e-03, -1.4241796e-03,  7.9841511e-03, -9.5540034e-03,\n",
              "       -7.8939823e-03, -7.0929802e-03, -3.7618123e-03,  5.5939187e-03,\n",
              "       -3.9453967e-03, -8.6634066e-03,  8.2592433e-03, -4.2620678e-03,\n",
              "        8.4403576e-03, -4.6694092e-03,  3.8038618e-03,  4.7841482e-03,\n",
              "        2.4747187e-03, -2.9532716e-03,  2.8547025e-03, -9.0460517e-03,\n",
              "       -2.6016242e-03, -2.5763903e-03,  7.4134874e-03, -3.5664972e-03,\n",
              "       -6.5009990e-03,  4.5518805e-03, -6.7771104e-04, -3.6508630e-03,\n",
              "        6.6508767e-03,  3.9717713e-03, -3.7194651e-03,  7.9636293e-04,\n",
              "        9.5401509e-03,  7.2580143e-03,  6.2282165e-03,  4.8800837e-03,\n",
              "        2.4801034e-03, -1.8851322e-03, -6.3009271e-03, -6.2097155e-04,\n",
              "       -1.4609639e-03, -9.0506708e-04, -6.4849467e-03,  7.3242290e-03,\n",
              "       -6.3958727e-03, -7.2686109e-03, -2.9057176e-03, -1.6300885e-03,\n",
              "       -7.4634571e-03,  8.7312696e-04, -5.3272196e-03, -1.4989752e-03,\n",
              "       -7.1619949e-03,  2.0371955e-03,  3.2798995e-03,  1.5396694e-06,\n",
              "       -5.3190347e-03, -1.7709233e-03,  6.7902189e-03,  3.8244438e-03,\n",
              "       -8.8010374e-03, -3.6540574e-03,  2.4982756e-03,  2.2304147e-03,\n",
              "       -9.5889429e-03,  4.8459629e-03, -8.5443510e-03, -7.2198184e-03,\n",
              "        3.1180668e-03, -3.0533427e-03,  3.4865625e-03,  9.1188783e-03,\n",
              "       -3.3542009e-03,  9.3127824e-03,  2.0871956e-03,  9.7777862e-03,\n",
              "        5.6847697e-03, -9.1137951e-03, -3.3150916e-03,  6.4091268e-03,\n",
              "        5.5136220e-03,  8.7123038e-03,  6.6096517e-03,  8.2730781e-03,\n",
              "       -1.0045644e-02,  4.1356180e-03, -4.5836344e-03,  3.6671152e-03,\n",
              "        6.2091118e-03,  4.5901071e-03,  8.0098845e-03,  1.5739414e-03,\n",
              "       -1.1632928e-03,  5.7619805e-03, -5.3577912e-03,  3.2108166e-04,\n",
              "        9.4498210e-03, -5.6132432e-03,  3.8039261e-03, -8.0230478e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.wv['machine'].shape"
      ],
      "metadata": {
        "id": "17j8nfWwo-xD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8f9059-dc42-44df-d7dd-f3774745da25"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podéis ver, es un vector de 100 dimensiones. Eso significa que hemos \"embutido\" (embebido, *embedded*) nuestras palabras en un espacio de 100 dimensiones.\n",
        "\n",
        "Veamos ahora algunas palabras similares:"
      ],
      "metadata": {
        "id": "jOqPU_GCo_n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_similares = word2vec.wv.most_similar('machine')\n",
        "for p in palabras_similares:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "QNO010E3knJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f45aad2-3c6e-4aa7-bc00-7e1557b2f694"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('network', 0.2733089327812195)\n",
            "('though', 0.154647096991539)\n",
            "('science', 0.14088661968708038)\n",
            "('among', 0.1399298757314682)\n",
            "('learning', 0.13779351115226746)\n",
            "('neural', 0.12052781879901886)\n",
            "('approach', 0.12033440172672272)\n",
            "('tagging', 0.1187024861574173)\n",
            "('although', 0.11561562865972519)\n",
            "('well', 0.11462866514921188)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No parece muy coherente...\n",
        "\n",
        "Hagamos un par de pruebas más para asegurarnos:"
      ],
      "metadata": {
        "id": "tMku1fZ_pVsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_similares = word2vec.wv.most_similar('artificial')\n",
        "for p in palabras_similares:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "zEhetSc9k1Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4b7c97-9b22-48d8-927c-7faf3b5ebc4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('study', 0.2848104238510132)\n",
            "('nlp', 0.22207187116146088)\n",
            "('proposed', 0.2208883911371231)\n",
            "('although', 0.22075864672660828)\n",
            "('commonly', 0.1981177181005478)\n",
            "('develop', 0.18781490623950958)\n",
            "('university', 0.16736182570457458)\n",
            "('many', 0.14883121848106384)\n",
            "('time', 0.14283111691474915)\n",
            "('since', 0.1407792568206787)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_similares = word2vec.wv.most_similar('intelligence')\n",
        "for p in palabras_similares:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "avDLPB9MkurU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5166d4-1f8e-4dd8-b502-73a96d49705b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('applied', 0.21009911596775055)\n",
            "('see', 0.21003179252147675)\n",
            "('grammar', 0.19884181022644043)\n",
            "('translation', 0.1929859071969986)\n",
            "('shared', 0.18842123448848724)\n",
            "('results', 0.17424318194389343)\n",
            "('models', 0.16210749745368958)\n",
            "('manipulating', 0.1433938890695572)\n",
            "('chinese', 0.1428874433040619)\n",
            "('information', 0.1411733478307724)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nada, definitivamente no parece funcionar muy bien.\n",
        "\n",
        "¿Qué está pasando?\n",
        "\n",
        "Pues que, por defecto, `Word2Vec` entrena el modelo subyacente (`CBOW` en nuestro caso, porque es el modelo por defecto y no hemos especificado lo contrario) durante 5 épocas. Esto puede ser poco, vamos a subirlo a 500 épocas.\n",
        "\n",
        "También podemos modificar otros parámetros interesantes, como:\n",
        "\n",
        "- `min_count`: el número mínimo de ocurrencias para que se considere cada palabra. Lo aumentaremos a 3.\n",
        "- `window`: el tamaño de la ventana de contexto. Por defecto es 5, vamos a subirlo a 9.\n",
        "- `vector_size`: las dimensiones del embedding. Vamos a subirlas a 120.\n",
        "- `sg`: 0 para modelo CBOW, 1 para modelo skip-gram.\n",
        "\n",
        "Vamos a ejecutar el modelo CBOW con una ventana de 9 y un embedding de 120 dimensiones, y a entrenarlo durante 500 épocas, a ver si mejora lo anterior:"
      ],
      "metadata": {
        "id": "2qNASZUupg7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "word2vec = Word2Vec([palabras], min_count=3, window=9, vector_size=120, epochs=500)"
      ],
      "metadata": {
        "id": "fGaX-kpLpwmg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos ahora qué tal el embedding:"
      ],
      "metadata": {
        "id": "LcmfGQsWqxmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_similares = word2vec.wv.most_similar('machine')\n",
        "for p in palabras_similares:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "vMjFPK1uqvnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e45fe6-7322-4580-fd79-cac914835aaa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('words', 0.9704554677009583)\n",
            "('hand', 0.9610974192619324)\n",
            "('hidden', 0.9591155052185059)\n",
            "('rules', 0.9571223855018616)\n",
            "('layer', 0.954377293586731)\n",
            "('learning', 0.9528979659080505)\n",
            "('network', 0.9366095066070557)\n",
            "('many', 0.9288315773010254)\n",
            "('word', 0.9116566181182861)\n",
            "('neural', 0.8856338262557983)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parece un poco más coherente.\n",
        "\n",
        "Veamos las otras:"
      ],
      "metadata": {
        "id": "mHBvE9Nzqvny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_similares = word2vec.wv.most_similar('artificial')\n",
        "for p in palabras_similares:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "KG2qTuB2qvnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a80b55-6ac9-4cae-8e1c-0ee6fec2d1ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ideas', 0.9404318928718567)\n",
            "('intelligence', 0.9397491812705994)\n",
            "('understanding', 0.8340374231338501)\n",
            "('computational', 0.8060718178749084)\n",
            "('linguistics', 0.7854410409927368)\n",
            "('computer', 0.78409743309021)\n",
            "('grammar', 0.7828748226165771)\n",
            "('science', 0.7649034857749939)\n",
            "('nlp', 0.763963520526886)\n",
            "('documents', 0.7522004842758179)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_similares = word2vec.wv.most_similar('intelligence')\n",
        "for p in palabras_similares:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "rO4o20N8qvnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43e4ce1-69f5-4925-dc4f-6643197c913e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('understanding', 0.9606847167015076)\n",
            "('artificial', 0.9397493004798889)\n",
            "('computer', 0.9393455982208252)\n",
            "('documents', 0.9207096695899963)\n",
            "('natural', 0.8635205626487732)\n",
            "('processing', 0.807485044002533)\n",
            "('language', 0.8044574856758118)\n",
            "('ideas', 0.7871613502502441)\n",
            "('linguistics', 0.6497765183448792)\n",
            "('computational', 0.6338580846786499)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nada mal, ¿no os parece?"
      ],
      "metadata": {
        "id": "FUt0ePLErDzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio\n",
        "\n",
        "Construid un modelo Word2Vec, usando el modelo **skip-gram**, para la página misma página de Wikipedia que hemos usado en el ejemplo.\n",
        "\n",
        "Comparad los resultados. ¿Qué opináis, funciona mejor o peor?"
      ],
      "metadata": {
        "id": "RtoiihNkrIs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Construcción del modelo Word2Vec con skip-gram\n",
        "word2vec_skip_gram = Word2Vec(sentences=[palabras], min_count=3, window=9, vector_size=120, epochs=500, sg=1)\n",
        "\n",
        "# Obtener palabras similares para 'machine'\n",
        "palabras_similares_skip_gram_machine = word2vec_skip_gram.wv.most_similar('machine')\n",
        "print(\"Palabras similares para 'machine' con skip-gram:\")\n",
        "for palabra in palabras_similares_skip_gram_machine:\n",
        "    print(palabra)\n",
        "\n",
        "# Obtener palabras similares para 'artificial'\n",
        "palabras_similares_skip_gram_artificial = word2vec_skip_gram.wv.most_similar('artificial')\n",
        "print(\"\\nPalabras similares para 'artificial' con skip-gram:\")\n",
        "for palabra in palabras_similares_skip_gram_artificial:\n",
        "    print(palabra)\n",
        "\n",
        "# Obtener palabras similares para 'intelligence'\n",
        "palabras_similares_skip_gram_intelligence = word2vec_skip_gram.wv.most_similar('intelligence')\n",
        "print(\"\\nPalabras similares para 'intelligence' con skip-gram:\")\n",
        "for palabra in palabras_similares_skip_gram_intelligence:\n",
        "    print(palabra)\n"
      ],
      "metadata": {
        "id": "VscKrecVl-g0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecbabee-56d4-4c2c-b666-122e7ab14a1c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras similares para 'machine' con skip-gram:\n",
            "('neural', 0.8453014492988586)\n",
            "('word', 0.833699107170105)\n",
            "('language', 0.815134584903717)\n",
            "('processing', 0.8082045316696167)\n",
            "('network', 0.8046045303344727)\n",
            "('words', 0.7754565477371216)\n",
            "('statistical', 0.767419695854187)\n",
            "('natural', 0.7642041444778442)\n",
            "('based', 0.750962495803833)\n",
            "('learning', 0.7434543371200562)\n",
            "\n",
            "Palabras similares para 'artificial' con skip-gram:\n",
            "('intelligence', 0.9548230767250061)\n",
            "('ideas', 0.9427052140235901)\n",
            "('computer', 0.6881476044654846)\n",
            "('documents', 0.674165666103363)\n",
            "('using', 0.655215322971344)\n",
            "('grammar', 0.6285039186477661)\n",
            "('approaches', 0.5711163282394409)\n",
            "('understanding', 0.567664623260498)\n",
            "('computational', 0.5438721179962158)\n",
            "('models', 0.5138964056968689)\n",
            "\n",
            "Palabras similares para 'intelligence' con skip-gram:\n",
            "('artificial', 0.9548231363296509)\n",
            "('ideas', 0.8619689345359802)\n",
            "('computer', 0.827447772026062)\n",
            "('documents', 0.8115591406822205)\n",
            "('understanding', 0.6916303634643555)\n",
            "('using', 0.5630097985267639)\n",
            "('language', 0.5412487387657166)\n",
            "('rules', 0.5366731882095337)\n",
            "('grammar', 0.531816840171814)\n",
            "('processing', 0.5292472839355469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En general, ambos modelos parecen funcionar bien en cuanto a la generación de palabras similares, pero hay algunas diferencias notables. El modelo skip-gram tiende a producir palabras más relacionadas con el contexto específico de procesamiento de lenguaje natural, mientras que CBOW parece capturar una gama más amplia de términos que incluyen tanto conceptos generales como específicos del campo.\n",
        "\n",
        "No hay una respuesta definitiva sobre cuál método funciona \"mejor\" ya que esto puede depender del contexto específico de la aplicación y de lo que se esté buscando en las representaciones vectoriales de las palabras. En este caso, parece que el modelo skip-gram podría ser más adecuado si estás interesado principalmente en términos específicos del procesamiento de lenguaje natural, mientras que CBOW podría ser más útil si buscas una variedad más amplia de términos relacionados."
      ],
      "metadata": {
        "id": "1jhMvRCZCzPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recursos:\n",
        "- https://www.kaggle.com/code/vipulgandhi/bag-of-words-model-for-beginners\n",
        "- https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031"
      ],
      "metadata": {
        "id": "WV_JVPYgPwm1"
      }
    }
  ]
}